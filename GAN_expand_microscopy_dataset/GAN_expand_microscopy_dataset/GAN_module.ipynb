{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "\n",
    "# A function to allow the user to select the folder contianing the data.\n",
    "# Function inputs args: None. \n",
    "# Function output 1: The path of that the folder selected by the user. \n",
    "def folder_selection_dialog():\n",
    "    root = Tk()\n",
    "    root.title('Please select the directory containing the images')\n",
    "    root.filename = filedialog.askdirectory(initialdir=\"/\", title=\"Select A Folder\")\n",
    "    directory = root.filename\n",
    "    root.destroy()\n",
    "\n",
    "    return directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Function to consider existing images, then crop them to a smaller size to make training a bit easier. This function will not be used within the RUNME files.\n",
    "def crop_images():\n",
    "    \n",
    "    # Select the directory with the images to crop. \n",
    "    directory = folder_selection_dialog()\n",
    "    \n",
    "    # Get a list of the images. \n",
    "    image_list = [_ for _ in os.listdir(directory) if 'C01' in _]\n",
    "    \n",
    "    # Make their folder. \n",
    "    if not os.path.exists(os.path.join(directory, 'smaller_images')):\n",
    "        os.makedirs(os.path.join(directory, 'smaller_images'))\n",
    "    \n",
    "    # Iterate through each of the images and get 4 smaller images from each.\n",
    "    x = 1\n",
    "    for i in range(len(image_list)): \n",
    "        \n",
    "        # Load in the image. \n",
    "        image_i = np.array(Image.open(os.path.join(directory, image_list[i])))\n",
    "        l = int(image_i.shape[0]/2)\n",
    "        \n",
    "        # Get the top left cropped image and save it. \n",
    "        image_TL = image_i[0:l,0:l] \n",
    "        im = Image.fromarray(image_TL)\n",
    "        im.save(os.path.join(directory, 'smaller_images', f'image_{str(x)}.tif'))\n",
    "        x += 1\n",
    "        \n",
    "        # Get the top right cropped image and save it.                      \n",
    "        image_TR = image_i[0:l,l:l*2]\n",
    "        im = Image.fromarray(image_TR)\n",
    "        im.save(os.path.join(directory, 'smaller_images', f'image_{str(x)}.tif'))\n",
    "        x += 1\n",
    "         \n",
    "        # Get the bottom left cropped image and save it.                      \n",
    "        image_BL = image_i[l:l*2,0:l]\n",
    "        im = Image.fromarray(image_BL)\n",
    "        im.save(os.path.join(directory, 'smaller_images', f'image_{str(x)}.tif'))\n",
    "        x += 1\n",
    "         \n",
    "        # Get the bottom right cropped image and save it.                      \n",
    "        image_BR = image_i[l:l*2,l:l*2]\n",
    "        im = Image.fromarray(image_BR)\n",
    "        im.save(os.path.join(directory, 'smaller_images', f'image_{str(x)}.tif'))\n",
    "        x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "\n",
    "# A function to allow the user to select the model they wish to use or retrain. \n",
    "# Function inputs args: None. \n",
    "# Function output 1: The file path of that which was selected by the user. \n",
    "def file_selection_dialog():\n",
    "    root = Tk()\n",
    "    root.title('Please select the machine learning model in question')\n",
    "    root.filename = filedialog.askopenfilename(initialdir=\"/\", title=\"Select A File\", filetypes=[(\"All files\", \"*.*\")])\n",
    "    file_path = root.filename\n",
    "    root.destroy()\n",
    "\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Function to display and save the training loss and validation loss per epoch.\n",
    "# Function input arg 1: training_loss --> Array of size 1 x num_epochs. This array contains the calculated values of loss for training. \n",
    "# Function input arg 2: validation_loss --> Array of size 1 x num_epochs. This array contains the calculated values of loss for validation. \n",
    "# Function input arg 3: save_plot --> True or Flase. When true, saves plot to data directory.  \n",
    "# Function input arg 4: display_plot --> True or Flase. When true, displays the plot. \n",
    "# Function input arg 5: directory --> The directory containing the training dataset. \n",
    "# Function input arg 6: date_time --> The datetime string in the format of 'YMD_HMS'. \n",
    "def loss_graph(training_loss, \n",
    "               validation_loss, \n",
    "               save_plot, \n",
    "               display_plot,\n",
    "               directory, \n",
    "               date_time):\n",
    "    \n",
    "    # Plot the loss per epoch. \n",
    "    y = list(range(0,len(training_loss)))\n",
    "    plt.plot(y, training_loss, label = \"Training loss\")\n",
    "    plt.plot(y, validation_loss, label = \"Validation loss\")\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    plt.ylabel('Loss', labelpad=10) # The labelpad argument alters the distance of the axis label from the axis itself. \n",
    "    plt.xlabel('Epoch', labelpad=10)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    # Save the plot if the user desires it.\n",
    "    if save_plot:\n",
    "        folder_name = f'training data_{date_time}'\n",
    "        if not os.path.exists(os.path.join(directory, folder_name)):\n",
    "            os.makedirs(os.path.join(directory, folder_name))\n",
    "        file_path = os.path.join(directory, folder_name, f'loss_{date_time}.png')\n",
    "        plt.savefig(file_path, dpi=200, bbox_inches='tight')\n",
    "    \n",
    "    # Display the plot if the user desires it. \n",
    "    if (display_plot == False):\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Function to display and save the training accuracy and validation accuracy per epoch.\n",
    "# Function input arg 1: training_accuracy --> Array of size 1 x num_epochs. This array contains the calculated values of training accuracy. \n",
    "# Function input arg 2: validation_accuracy --> Array of size 1 x num_epochs. This array contains the calculated values of validation accuracy. \n",
    "# Function input arg 3: save_plot --> True or Flase. When true, saves plot to data directory.  \n",
    "# Function input arg 4: display_plot --> True or Flase. When true, displays the plot. \n",
    "# Function input arg 5: directory --> The directory containing the training dataset. \n",
    "# Function input arg 6: date_time --> The datetime string in the format of 'YMD_HMS'. \n",
    "def accuracy_graph(training_accuracy, \n",
    "                   validation_accuracy, \n",
    "                   save_plot, \n",
    "                   display_plot,\n",
    "                   directory, \n",
    "                   date_time):\n",
    "    \n",
    "    # Plot the BCE calculated loss per epoch. \n",
    "    y = list(range(0,len(training_accuracy)))\n",
    "    plt.plot(y, training_accuracy, label=\"Training accuracy\")\n",
    "    plt.plot(y, validation_accuracy, label=\"Validation accuracy\")\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    plt.ylabel('Accuracy', labelpad=10) # The leftpad argument alters the distance of the axis label from the axis itself. \n",
    "    plt.xlabel('Epoch', labelpad=10)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    # Save the plot if the user desires it.\n",
    "    if save_plot:\n",
    "        folder_name = f'training data_{date_time}'\n",
    "        if not os.path.exists(os.path.join(directory, folder_name)):\n",
    "            os.makedirs(os.path.join(directory, folder_name))\n",
    "        file_path = os.path.join(directory, folder_name, f'accuracy_{date_time}.png')\n",
    "        plt.savefig(file_path, dpi=200, bbox_inches='tight')\n",
    "    \n",
    "    # Display the plot if the user desires it. \n",
    "    if (display_plot == False):\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from tqdm import trange \n",
    "import os\n",
    "\n",
    "# A function which will append images within a directory into a numpy array.\n",
    "# Function input 1: image_list [list of strings] --> Each item in the list is the name of an image which needs to be appended into one stack e.g. image1.tif.\n",
    "# Function input 2: directory [string] --> The directory containing the images.\n",
    "# Function output 1: image stack [numpy array] --> The 3D stack of appended images. \n",
    "def append_images(image_list,\n",
    "                  directory):\n",
    "\n",
    "    # Create an empty list. \n",
    "    image_stack = []\n",
    "    \n",
    "    # Iterate through the images of our list and append them to our stack. \n",
    "    for i in trange(len(image_list)):\n",
    "        file_path = os.path.join(directory, image_list[i])\n",
    "        img = cv2.imread(file_path, -1)\n",
    "        \n",
    "        # Scale the image between -1 and 1. \n",
    "        img = np.interp(img, (img.min(), img.max()), (-1, +1))\n",
    "        \n",
    "        # Höfener, H., Homeyer, A., Weiss, N., Molin, J., Lundström, C.F. and Hahn, H.K., 2018. Deep learning nuclei detection: A simple approach can deliver state-of-the-art results. Computerized Medical Imaging and Graphics, 70, pp.43-52.\n",
    "        # Rotate the images. \n",
    "        for rot in range(2):\n",
    "            img2 = np.rot90(img, rot)\n",
    "        \n",
    "            # Mirror the data horizontally...\n",
    "            for h in range(2):\n",
    "                if h == 0: \n",
    "                    img3 = img2\n",
    "                else:\n",
    "                    img3 = np.flip(img2, axis=0) \n",
    "\n",
    "                # ... and vertically. \n",
    "                for v in range(2):\n",
    "                    if v == 0: \n",
    "                        img4 = img3\n",
    "                    else: \n",
    "                        img4 = np.flip(img3, axis=1)\n",
    "\n",
    "                    # Add an extra axis (for processing later) and append our image to the stack.\n",
    "                    img4 = np.stack((img4,)*1, axis=-1)\n",
    "                    image_stack.append(img4)\n",
    "\n",
    "    # Convert the stack to a numpy array. \n",
    "    image_stack = np.asarray(image_stack)\n",
    "\n",
    "    return image_stack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "# Funtion to create our generator. \n",
    "# Function input 1: latent_size [int] --> Size of the 1D latent space vector. \n",
    "# Function input 2: img_height [int] --> Image height in pixels. \n",
    "# Function input 3: img_width [int] --> Image width in pixels. \n",
    "# Function output 1: model --> The untrained model. \n",
    "def create_generator(latent_size,\n",
    "                     img_height\n",
    "                     img_width):\n",
    "\n",
    "    # Create the backbone for our sequential model.\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First, we need to create smaller images which can be upscaled.\n",
    "    # We're going to start with 4x4 images. \n",
    "    # To add redundancy to our model, we'll make 25 such images. \n",
    "    # Thus, in total, we'll need 400 nodes we we can then reshape. \n",
    "    model.add(Dense(400, input_dim=latent_size))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape(4,4,100))\n",
    "    \n",
    "    # Updample to 8x8: use 50 differnt convolutions, of size 4x4. \n",
    "    model.add(Conv2DTranspose(50, (4,4), strides=(2,2), padding='same')\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Upsample to 16x16: use 50 differnt convolutions, of size 4x4. \n",
    "    model.add(Conv2DTranspose(50, (4,4), strides=(2,2), padding='same')\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Upsample to 32x32: use 50 differnt convolutions, of size 4x4. \n",
    "    model.add(Conv2DTranspose(50, (4,4), strides=(2,2), padding='same')\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Upsample to 64x64: use 50 differnt convolutions, of size 4x4. \n",
    "    model.add(Conv2DTranspose(50, (4,4), strides=(2,2), padding='same')\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Upsample to 128x128: use 50 differnt convolutions, of size 4x4. \n",
    "    model.add(Conv2DTranspose(50, (4,4), strides=(2,2), padding='same')\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Upsample to 256x256: use 50 differnt convolutions, of size 4x4. \n",
    "    model.add(Conv2DTranspose(50, (4,4), strides=(2,2), padding='same')\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Upsample to 512x512: use 50 differnt convolutions, of size 4x4. \n",
    "    model.add(Conv2DTranspose(50, (4,4), strides=(2,2), padding='same')\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Upsample to 1024x1024: use 50 differnt convolutions, of size 4x4. \n",
    "    model.add(Conv2DTranspose(50, (4,4), strides=(2,2), padding='same')\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Create our output layer.\n",
    "    # Use a tanh activation to scale our pixel values between -1 and +1. \n",
    "    model.add(Conv2D(1, (3,3), activation='tanh', padding='same'))\n",
    "    \n",
    "    # Return the model as the function output. \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "# Function to create the latent space (the generator's input). \n",
    "# Function input 1: latent_dimension [int] --> The size of the latent dimension for a single sample. In my case, it's 100.\n",
    "# Function input 2: number_of_samples [int] --> The number of samples for which we need to create a latent space. \n",
    "# Function output: latent_space [array] --> The latent spaces for all the samples. \n",
    "def create_latent_space(latent_dimension,\n",
    "                        number_of_samples): \n",
    "    \n",
    "    # First, we must create random numbers adhering to a normal (gaussian) distribution.\n",
    "    latent_space = np.random.randn(latent_dimension * number_of_samples)\n",
    "    \n",
    "    # Reshape the vector or numbers to a 2D array, such that it can be used to represent numerous samples.\n",
    "    latent_space = latent_space.reshape(number_of_samples, latent_dimension)\n",
    "    \n",
    "    return latent_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "# Function to create fake images using our generator. \n",
    "# Function input 1: generator_model --> The generator model.\n",
    "# Function input 2: latent_dimension [int] --> The size of the latent dimension for a single sample. In my case, it's 100.\n",
    "# Function input 3: number_of_samples [int] --> The number of samples for which we need to create a latent space. \n",
    "def make_fake_images(generator_model,\n",
    "                     latent_dimension,\n",
    "                     number_of_samples):\n",
    "    \n",
    "    # Create the latent space(s).\n",
    "    latent_spaces = create_latent_space(latent_dimension, number_of_samples)\n",
    "    \n",
    "    # Use our model to create fake images. \n",
    "    fake_images = generator_model.predict(latent_spaces)\n",
    "    \n",
    "    # Create the corresponding 'fake' class labels (0).\n",
    "    fake_image_labels = np.zeros(number_of_sampels, 1)\n",
    "    \n",
    "    return fake_images, fake_image_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequentialial\n",
    "from keras.layers import \n",
    "# Function to create the discriminator. \n",
    "# Function input arg 1: img_height [int] --> The pixel height of the image.\n",
    "# Function input arg 2: img_width [int] --> The pixels width of the image. \n",
    "# Function input arg 3: img_channels [int] --> The number of channels to the image. \n",
    "def create_discriminator(img_height,\n",
    "                        img_width,\n",
    "                        img_channels): \n",
    "    \n",
    "    # Define the input shape of our images. \n",
    "    image_shape = (img_height, img_width, img_channels)\n",
    "    \n",
    "    # Create an instance of a sequential model. \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Create a normal convolutional layer. \n",
    "    model.add(Conv2d(64, (3,3), padding='same', input_shape=image_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Downsample our input to 512 x 512. \n",
    "    model.add(Conv2d(32, (3,3), strides=(2,2), padding='same', input_shape=image_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Downsample our input to 256 x 256. \n",
    "    model.add(Conv2d(32, (3,3), strides=(2,2), padding='same', input_shape=image_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Downsample our input to 128 x 128. \n",
    "    model.add(Conv2d(32, (3,3), strides=(2,2), padding='same', input_shape=image_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Downsample our input to 64 x 64. \n",
    "    model.add(Conv2d(32, (3,3), strides=(2,2), padding='same', input_shape=image_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "        \n",
    "    # Downsample our input to 32 x 32. \n",
    "    model.add(Conv2d(64, (3,3), strides=(2,2), padding='same', input_shape=image_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Downsample our input to 16 x 16. \n",
    "    model.add(Conv2d(128, (3,3), strides=(2,2), padding='same', input_shape=image_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Downsample our input to 8 x 8. \n",
    "    model.add(Conv2d(256, (3,3), strides=(2,2), padding='same', input_shape=image_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Downsample our input to 4 x 4. \n",
    "    model.add(Conv2d(256, (3,3), strides=(2,2), padding='same', input_shape=image_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Create the classifier. \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model. \n",
    "    optim = Adam(lr=0.002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optim, metrics=['accuracy', 'loss'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt \n",
    "\n",
    "# Function to train the GAN. \n",
    "def train_GAN(directory\n",
    "             file_type = '.tif'):\n",
    "    \n",
    "    ### (1) Establish variables useful for the rest of the code. \n",
    "    \n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    ### (2) Load in the 'real' dataset. \n",
    "    \n",
    "    image_list = [_ for _ in os.listdir(directory) if file_type in _]\n",
    "    real_images = append_images(image_list,\n",
    "                                directory)\n",
    "    \n",
    "    ### (3) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images to 1024. \n",
    "\n",
    "# Add dropout to the generator and the discriminator. \n",
    "\n",
    "# Figure out how the laent space (which is 2d now) can feed into the model. \n",
    "# I think it should only accept 1d shapes, might be wrong. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
