{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "\n",
    "# A function to allow the user to select the folder contianing the data.\n",
    "# Function inputs args: None. \n",
    "# Function output 1: The path of that the folder selected by the user. \n",
    "def folder_selection_dialog():\n",
    "    root = Tk()\n",
    "    root.title('Please select the directory containing the images')\n",
    "    root.filename = filedialog.askdirectory(initialdir=\"/\", title=\"Select A Folder\")\n",
    "    directory = root.filename\n",
    "    root.destroy()\n",
    "\n",
    "    return directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Function to consider existing images, then crop them to a smaller size to make training a bit easier. This function will not be used within the RUNME files.\n",
    "def crop_images():\n",
    "    \n",
    "    # Select the directory with the images to crop. \n",
    "    directory = folder_selection_dialog()\n",
    "    \n",
    "    # Get a list of the images. \n",
    "    image_list = [_ for _ in os.listdir(directory) if 'C01.tif' in _]\n",
    "    \n",
    "    # Make their folder. \n",
    "    if not os.path.exists(os.path.join(directory, 'smaller_images')):\n",
    "        os.makedirs(os.path.join(directory, 'smaller_images'))\n",
    "    \n",
    "    # Iterate through each of the images and get 4 smaller images from each.\n",
    "    x = 1\n",
    "    for i in range(len(image_list)): \n",
    "        \n",
    "        # Load in the image. \n",
    "        image_i = np.array(Image.open(os.path.join(directory, image_list[i])))\n",
    "        l = 1024 # This is an arbitrary value, selected for ease of building this model and developing this skill set. \n",
    "        \n",
    "        # Get the top left cropped image and save it. \n",
    "        image_TL = image_i[0:l,0:l] \n",
    "        im = Image.fromarray(image_TL)\n",
    "        im.save(os.path.join(directory, 'smaller_images', f'image_{str(x)}.tif'))\n",
    "        x += 1\n",
    "        \n",
    "        # Get the top right cropped image and save it.                      \n",
    "        image_TR = image_i[0:l,l:l*2]\n",
    "        im = Image.fromarray(image_TR)\n",
    "        im.save(os.path.join(directory, 'smaller_images', f'image_{str(x)}.tif'))\n",
    "        x += 1\n",
    "         \n",
    "        # Get the bottom left cropped image and save it.                      \n",
    "        image_BL = image_i[l:l*2,0:l]\n",
    "        im = Image.fromarray(image_BL)\n",
    "        im.save(os.path.join(directory, 'smaller_images', f'image_{str(x)}.tif'))\n",
    "        x += 1\n",
    "         \n",
    "        # Get the bottom right cropped image and save it.                      \n",
    "        image_BR = image_i[l:l*2,l:l*2]\n",
    "        im = Image.fromarray(image_BR)\n",
    "        im.save(os.path.join(directory, 'smaller_images', f'image_{str(x)}.tif'))\n",
    "        x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "\n",
    "# A function to allow the user to select the model they wish to use or retrain. \n",
    "# Function inputs args: None. \n",
    "# Function output 1: The file path of that which was selected by the user. \n",
    "def file_selection_dialog():\n",
    "    root = Tk()\n",
    "    root.title('Please select the machine learning model in question')\n",
    "    root.filename = filedialog.askopenfilename(initialdir=\"/\", title=\"Please select the machine learning model in question\", filetypes=[(\"All files\", \"*.*\")])\n",
    "    file_path = root.filename\n",
    "    root.destroy()\n",
    "\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Function to display and save the training loss and validation loss per epoch.\n",
    "# Function input arg 1: discriminator_training_loss_real --> Array of size 1 x num_epochs. This array contains the calculated values of loss for training. \n",
    "# Function input arg 2: discriminator_training_loss_fake --> Array of size 1 x num_epochs. This array contains the calculated values of loss for training. \n",
    "# Function input arg 3: generator_training_loss --> Array of size 1 x num_epochs. This array contains the calculated values of loss for training. \n",
    "# Function input arg 4: discriminator_testing_loss_real --> Array of size 1 x num_epochs. This array contains the calculated values of loss for training. \n",
    "# Function input arg 5: discriminator_testing_loss_fake --> Array of size 1 x num_epochs. This array contains the calculated values of loss for training. \n",
    "# Function input arg 6: save_data --> True or Flase. When true, saves plot to data directory.  \n",
    "# Function input arg 7: display_plot --> True or Flase. When true, displays the plot. \n",
    "# Function input arg 8: directory --> The directory containing the training dataset. \n",
    "# Function input arg 9: date_time --> The datetime string in the format of 'YMD_HMS'. \n",
    "def loss_graph(discriminator_training_loss_real, \n",
    "               discriminator_training_loss_fake,\n",
    "               generator_training_loss,\n",
    "               discriminator_testing_loss_real,\n",
    "               discriminator_testing_loss_fake,\n",
    "               save_data, \n",
    "               display_plot,\n",
    "               directory, \n",
    "               date_time):\n",
    "    \n",
    "    # Plot the loss per epoch. \n",
    "    y = list(range(0,len(discriminator_training_loss_real)))\n",
    "    plt.plot(y, discriminator_training_loss_real, label = \"Discriminator (training) loss real\", color='blue')\n",
    "    plt.plot(y, discriminator_training_loss_fake, label = \"Discriminator (training) loss fake\", color='dodgerblue')\n",
    "    plt.plot(y, generator_training_loss, label = \"Generator loss\", color='fuchsia')\n",
    "    plt.plot(y, discriminator_testing_loss_real, label = \"Discriminator (test) loss real\", color='darkred')\n",
    "    plt.plot(y, discriminator_testing_loss_fake, label = \"Discriminator (test) loss fake\", color='indianred')\n",
    "\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    plt.ylabel('Loss', labelpad=10) # The labelpad argument alters the distance of the axis label from the axis itself. \n",
    "    plt.xlabel('Epoch', labelpad=10)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    # Save the plot if the user desires it.\n",
    "    if save_data:\n",
    "        folder_name = f'training data_{date_time}'\n",
    "        if not os.path.exists(os.path.join(directory, folder_name)):\n",
    "            os.makedirs(os.path.join(directory, folder_name))\n",
    "        file_path = os.path.join(directory, folder_name, f'loss_{date_time}.png')\n",
    "        plt.savefig(file_path, dpi=200, bbox_inches='tight')\n",
    "    \n",
    "    # Display the plot if the user desires it. \n",
    "    if (display_plot == False):\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Function to display and save the training accuracy and validation accuracy per epoch.\n",
    "# Function input arg 1: discriminator_training_accuracy_real --> Array of size 1 x num_epochs. This array contains the calculated values of loss for training. \n",
    "# Function input arg 2: discriminator_training_accuracy_fake --> Array of size 1 x num_epochs. This array contains the calculated values of loss for training. \n",
    "# Function input arg 3: discriminator_testing_accuracy_real --> Array of size 1 x num_epochs. This array contains the calculated values of loss for training. \n",
    "# Function input arg 4: discriminator_testing_accuracy_fake --> Array of size 1 x num_epochs. This array contains the calculated values of loss for training. \n",
    "# Function input arg 5: save_data --> True or Flase. When true, saves plot to data directory.  \n",
    "# Function input arg 6: display_plot --> True or Flase. When true, displays the plot. \n",
    "# Function input arg 7: directory --> The directory containing the training dataset. \n",
    "# Function input arg 8: date_time --> The datetime string in the format of 'YMD_HMS'. \n",
    "def accuracy_graph(discriminator_training_accuracy_real, \n",
    "                   discriminator_training_accuracy_fake,\n",
    "                   discriminator_testing_accuracy_real,\n",
    "                   discriminator_testing_accuracy_fake, \n",
    "                   save_data, \n",
    "                   display_plot,\n",
    "                   directory, \n",
    "                   date_time):\n",
    "    \n",
    "    # Plot the accuracy per epoch. \n",
    "    y = list(range(0,len(discriminator_training_accuracy_real)))\n",
    "    plt.plot(y, discriminator_training_accuracy_real, label = \"Discriminator (training) accuracy real\", color='blue')\n",
    "    plt.plot(y, discriminator_training_accuracy_fake, label = \"Discriminator (training) accuracy fake\", color='dodgerblue')\n",
    "    plt.plot(y, discriminator_testing_accuracy_real, label = \"Discriminator (test) accuracy real\", color='darkred')\n",
    "    plt.plot(y, discriminator_testing_accuracy_fake, label = \"Discriminator (test) accuracy fake\", color='indianred')\n",
    "\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    plt.ylabel('Accuracy', labelpad=10) # The leftpad argument alters the distance of the axis label from the axis itself. \n",
    "    plt.xlabel('Epoch', labelpad=10)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    # Save the plot if the user desires it.\n",
    "    if save_data:\n",
    "        folder_name = f'training data_{date_time}'\n",
    "        if not os.path.exists(os.path.join(directory, folder_name)):\n",
    "            os.makedirs(os.path.join(directory, folder_name))\n",
    "        file_path = os.path.join(directory, folder_name, f'accuracy_{date_time}.png')\n",
    "        plt.savefig(file_path, dpi=200, bbox_inches='tight')\n",
    "    \n",
    "    # Display the plot if the user desires it. \n",
    "    if (display_plot == False):\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import os\n",
    "from math import floor \n",
    "\n",
    "# A function which will append images within a directory into a numpy array.\n",
    "# Function input 1: directory [string] --> The directory containing the images.\n",
    "# Function input 2: file_type [string] --> The file type of the training images e.g. '.tif'.\n",
    "# Function input 3: indices [list] --> The list of image indices to indicate which images and which transformations to use. \n",
    "# Function output 1: image stack [numpy array] --> The 3D stack of appended images. \n",
    "def append_images(directory,\n",
    "                  file_type,\n",
    "                  indices):\n",
    "\n",
    "    # Create an empty list. \n",
    "    image_stack = []\n",
    "    \n",
    "    # Iterate through the images of our list and append them to our stack. \n",
    "    for i in range(len(indices)):\n",
    "        \n",
    "        # Determine which unmodified image we need to use. \n",
    "        image_number = floor(indices[i]/8)+1\n",
    "        image_name = f\"image_{str(image_number)}{file_type}\"\n",
    "        \n",
    "        file_path = os.path.join(directory, image_name)\n",
    "        img = cv2.imread(file_path, -1)\n",
    "        \n",
    "        # Scale the image between -1 and 1. \n",
    "        img = np.interp(img, (img.min(), img.max()), (-1, +1))\n",
    "        \n",
    "        # Determine which transformation to apply. \n",
    "        transformation_1 = (indices[i]) % 8\n",
    "        transformation_2 = (indices[i]) % 4\n",
    "        \n",
    "        # Rotation\n",
    "        if 0 <= transformation_1 <= 3:\n",
    "            img = np.rot90(img, 1)\n",
    "        \n",
    "        # Horizontal flipping.\n",
    "        if 1 <= transformation_2 <= 2:\n",
    "            img = np.flip(img, axis=0) \n",
    "        \n",
    "        # Vertical flipping.\n",
    "        if 2 <= transformation_2 <= 3:\n",
    "            img = np.flip(img, axis=1) \n",
    "\n",
    "        # Add an extra axis (for processing later) and append our image to the stack.\n",
    "        img = np.stack((img,)*1, axis=-1)\n",
    "        image_stack.append(img)\n",
    "\n",
    "    # Convert the stack to a numpy array. \n",
    "    image_stack = np.asarray(image_stack)\n",
    "\n",
    "    return image_stack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LeakyReLU, Reshape, Conv2DTranspose, Conv2D, Dropout, BatchNormalization\n",
    "\n",
    "# Funtion to create our generator. \n",
    "# Function input 1: latent_length [int] --> Size of the 1D latent space vector. \n",
    "# Function input 2: img_height [int] --> Image height in pixels. \n",
    "# Function input 3: img_width [int] --> Image width in pixels. \n",
    "# Function output 1: model --> The untrained model. \n",
    "def create_generator(latent_length,\n",
    "                     img_height,\n",
    "                     img_width):\n",
    "    \n",
    "    # Create the backbone for our sequential model.\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First, we need to create smaller 4x4 images which can be upscaled.\n",
    "    # To add redundancy to our model, we'll make 'i' such images. \n",
    "    n_nodes = 4 * 4 * 32\n",
    "    model.add(Dense(n_nodes, input_dim=latent_length))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # We then need to reshape this Dense layer from a single dimension to 3 dimensions. \n",
    "    model.add(Reshape((4,4,32)))\n",
    "    \n",
    "    # Updample to 8x8: use 32 differnt convolutions, of size 4x4. \n",
    "    model.add(Conv2DTranspose(32, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    # Upsample to 16x16: use 32 differnt convolutions, of size 4x4. \n",
    "    model.add(Conv2DTranspose(32, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    # Upsample to 32x32: use 32 differnt convolutions, of size 4x4. \n",
    "    model.add(Conv2DTranspose(32, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    # Upsample to 64x64: use 32 differnt convolutions, of size 4x4. \n",
    "    model.add(Conv2DTranspose(32, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    # Upsample to 128x128: use 32 differnt convolutions, of size 4x4. \n",
    "    model.add(Conv2DTranspose(32, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    # Upsample to 256x256: use 32 differnt convolutions, of size 4x4. \n",
    "    model.add(Conv2DTranspose(32, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    # Upsample to 512x512: use 32 differnt convolutions, of size 4x4. \n",
    "    model.add(Conv2DTranspose(32, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    # Upsample to 1024x1024: use 32 differnt convolutions, of size 4x4. \n",
    "    model.add(Conv2DTranspose(32, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    # Create our output layer.\n",
    "    # Use a tanh activation to scale our pixel values between -1 and +1. \n",
    "    model.add(Conv2D(1, (3,3), activation='tanh', padding='same'))\n",
    "    \n",
    "    # Return the model as the function output. \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "# Function to create the latent space (the generator's input). \n",
    "# Function input 1: latent_length [int] --> The size of the latent dimension for a single sample. In my case, it's 100.\n",
    "# Function input 2: number_of_samples [int] --> The number of samples for which we need to create a latent space. \n",
    "# Function output: latent_space [array] --> The latent spaces for all the samples. \n",
    "def create_latent_space(latent_length,\n",
    "                        number_of_samples): \n",
    "    \n",
    "    # First, we must create random numbers adhering to a normal (gaussian) distribution.\n",
    "    latent_space = np.random.randn(latent_length * number_of_samples)\n",
    "    \n",
    "    # Reshape the vector or numbers to a 2D array, such that it can be used to represent numerous samples.\n",
    "    latent_space = latent_space.reshape(number_of_samples, latent_length)\n",
    "    \n",
    "    return latent_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "# Function to create fake images using our generator. \n",
    "# Function input 1: generator_model --> The generator model.\n",
    "# Function input 2: latent_length [int] --> The size of the latent dimension for a single sample. In my case, it's 100.\n",
    "# Function input 3: number_of_samples [int] --> The number of samples for which we need to create a latent space. \n",
    "def make_fake_images(generator_model,\n",
    "                     latent_length,\n",
    "                     number_of_samples):\n",
    "    \n",
    "    # Create the latent space(s).\n",
    "    latent_space = create_latent_space(latent_length, number_of_samples)\n",
    "    \n",
    "    # Use our model to create fake images. \n",
    "    fake_images = generator_model.predict(latent_space)\n",
    "    \n",
    "    # Create the corresponding 'fake' class labels (0).\n",
    "    fake_image_labels = np.zeros((number_of_samples, 1))\n",
    "    \n",
    "    return fake_images, fake_image_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Function to select and return a subset of the real images. \n",
    "# Function input 1: num_requested_images [int] --> The number of images you need from the total array. \n",
    "# Function input 2: unused images_indices [list] --> The unused image indexes.\n",
    "# Function output 1: unused_images_indices [list] --> List of image indices which have not yet been used.\n",
    "# Function output 2: real_images_subset [array] --> Array of the real images, organised as [number_of_images, heigth, width, channels].\n",
    "# Function output 3: real_images_labels [array] --> Array of 1s, of the same length as the number of images.\n",
    "def return_real_images(num_requested_images,\n",
    "                       unused_images_indices):\n",
    "    \n",
    "    # Get the minimum and maximum.\n",
    "    number_of_idx = len(unused_images_indices)\n",
    "    \n",
    "    # If we have sufficient images to take a selection from. \n",
    "    if num_requested_images < len(unused_images_indices):\n",
    "        \n",
    "        # Get the indices to select the indices.\n",
    "        indices = random.sample(range(number_of_idx), num_requested_images)\n",
    "        \n",
    "        # Get the corresponding images. \n",
    "        real_images_subset = append_images(directory,\n",
    "                                           file_type,\n",
    "                                           indices)\n",
    "        \n",
    "        # Remove these indices from the unused_images_indices. \n",
    "        unused_images_indices = [_ for _ in unused_images_indices if _ not in indices]\n",
    "\n",
    "        # Get the real image labels.\n",
    "        real_images_labels = np.ones(real_images_subset.shape[0]) \n",
    "        \n",
    "    # If we have an insifficient number of images, take whatever is left. \n",
    "    else:\n",
    "    \n",
    "        # Get the rest of the real images. \n",
    "        real_images_subset = append_images(directory,\n",
    "                                           file_type,\n",
    "                                           unused_images_indices)\n",
    "\n",
    "        # Clear out unused_images_indices.\n",
    "        unused_images_indices = [] \n",
    "        \n",
    "        # Get the real image labels.\n",
    "        real_images_labels = np.ones(real_images_subset.shape[0]) \n",
    "        \n",
    "    return unused_images_indices, real_images_subset, real_images_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dropout, LeakyReLU, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Function to create the discriminator. \n",
    "# Function input arg 1: img_height [int] --> The pixel height of the image.\n",
    "# Function input arg 2: img_width [int] --> The pixels width of the image. \n",
    "# Function input arg 3: img_channels [int] --> The number of channels to the image. \n",
    "def create_discriminator(img_height,\n",
    "                         img_width,\n",
    "                         img_channels): \n",
    "    \n",
    "    # Define the input shape of our images. \n",
    "    image_shape = (img_height, img_width, img_channels)\n",
    "    \n",
    "    # Create an instance of a sequential model. \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Create a normal convolutional layer. \n",
    "    model.add(Conv2D(32, (3,3), padding='same', input_shape=image_shape))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Downsample our input to 512 x 512. \n",
    "    model.add(Conv2D(32, (3,3), strides=(2,2), padding='same', input_shape=image_shape))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Downsample our input to 256 x 256. \n",
    "    model.add(Conv2D(32, (3,3), strides=(2,2), padding='same', input_shape=image_shape))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Downsample our input to 128 x 128. \n",
    "    model.add(Conv2D(32, (3,3), strides=(2,2), padding='same', input_shape=image_shape))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Downsample our input to 64 x 64. \n",
    "    model.add(Conv2D(32, (3,3), strides=(2,2), padding='same', input_shape=image_shape))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "        \n",
    "    # Downsample our input to 32 x 32. \n",
    "    model.add(Conv2D(64, (3,3), strides=(2,2), padding='same', input_shape=image_shape))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Downsample our input to 16 x 16. \n",
    "    model.add(Conv2D(64, (3,3), strides=(2,2), padding='same', input_shape=image_shape))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Downsample our input to 8 x 8. \n",
    "    model.add(Conv2D(64, (3,3), strides=(2,2), padding='same', input_shape=image_shape))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Downsample our input to 4 x 4. \n",
    "    model.add(Conv2D(64, (3,3), strides=(2,2), padding='same', input_shape=image_shape))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Create the classifier. \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model. \n",
    "    optim = Adam(learning_rate=0.002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Function to combine the generator and the discriminator, such that the generator can be trained. \n",
    "# Function input 1: [model instance] --> the \n",
    "def create_GAN(generator_model, \n",
    "               discriminator_model): \n",
    "    \n",
    "    # First, prevent the discriminator from training.\n",
    "    discriminator_model.trainable = False \n",
    "    \n",
    "    # Combine the two models with a sequential model. \n",
    "    model = Sequential()\n",
    "    model.add(generator_model)\n",
    "    model.add(discriminator_model)\n",
    "    \n",
    "    # Compile the model.\n",
    "    optim = Adam(learning_rate=0.002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optim)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil \n",
    "import pandas as pd\n",
    "import os as os \n",
    "from tqdm import trange\n",
    "\n",
    "# Function to train the generator and the discriminator.\n",
    "# Function input arg 1: generator_model [model] --> The generator. \n",
    "# Function input arg 2: discriminator_model [model] --> The discriminator. \n",
    "# Function input arg 2: gan_model [model] --> The GAN. \n",
    "# Function input arg 3: latent_length [int] --> The size of the latent space. \n",
    "# Function input arg 4: num_epochs [int] --> The number of epochs to train for. \n",
    "# Function input arg 5: batch_size [int, preferbly even] --> Num images processed per batch. NB: Your batch size can never equal more than 2*\n",
    "# Function input arg 6: directory [string] --> The directory containing the training images. \n",
    "# Fucntion input arg 7: file_type [string] --> The file type of the training images. \n",
    "# Function input arg 8: test_train_split [float] --> The fraction of the data which will be used for training. e.g. 0.8 would mean 80% be used for training, while 20% for testing.\n",
    "# Function input arg 9: date_time [string] --> A date time string organised as 'YYYYMMDD_HHMMSS'. \n",
    "# Function input arg 10: training_data [DataFrame] --> The pandas DataFrame of training data.\n",
    "# Function input arg 10: save_data [bool] --> When True, saves the models and the training data.\n",
    "# Function output 1: training_Data [DataFrame] --> The pandas DataFrame of training data. \n",
    "def train_GAN(generator_model, \n",
    "              discriminator_model,\n",
    "              gan_model,\n",
    "              latent_length,\n",
    "              num_epochs,\n",
    "              batch_size, \n",
    "              directory, \n",
    "              file_type, \n",
    "              test_train_split,\n",
    "              date_time, \n",
    "              save_data, \n",
    "              training_data):\n",
    "    \n",
    "    # Re-create the list of indexes for the images (which haven't been used for training) at the start of each epoch (it changes with each batch). \n",
    "    unused_images_indices = []\n",
    "    img_in_dir = len([_ for _ in os.listdir(directory) if file_type in _])\n",
    "    for i in range(img_in_dir*8):\n",
    "        unused_images_indices.append(i)\n",
    "    random.shuffle(unused_images_indices)\n",
    "    \n",
    "    # Get the list of image (indices) for testing. \n",
    "    test_unused_images_indices = unused_images_indices[(int(test_train_split * len(unused_images_indices))):len(unused_images_indices)]\n",
    "\n",
    "    # Calculate the number of batches per epoch.\n",
    "    num_batches = int((test_train_split * len(unused_images_indices)) / (batch_size * 0.5))\n",
    "    \n",
    "    # Loop through each epoch and train the model. \n",
    "    for i in (x := trange(num_epochs)):\n",
    "        print(f'Epoch: {str(i+1)} of {str(num_epochs)}')\n",
    "        # Set the description for the trange progress bar. \n",
    "        x.set_description(f\"Training GAN model. Epoch number:{str(i)}\")\n",
    "          \n",
    "        # Create / reset the image indices.\n",
    "        train_unused_images_indices = unused_images_indices[0:(int(test_train_split * len(unused_images_indices)))]\n",
    "\n",
    "        # Create empty lists for storing training data. \n",
    "        batch_discriminator_train_loss_real = []\n",
    "        batch_discriminator_train_loss_fake = []\n",
    "        batch_discriminator_train_accuracy_real = []\n",
    "        batch_discriminator_train_accuracy_fake = [] \n",
    "        batch_generator_train_loss = []\n",
    "        \n",
    "        batch_discriminator_test_loss_real = []\n",
    "        batch_discriminator_test_loss_fake = []\n",
    "        batch_discriminator_test_accuracy_real = []\n",
    "        batch_discriminator_test_accuracy_fake = [] \n",
    "        \n",
    "        # Loop though each batch and train the model.\n",
    "        for t in range(num_batches): \n",
    "\n",
    "            print(f'   Batch: {str(t+1)} of {str(num_batches)}')\n",
    "            ###########################\n",
    "            # TRAIN THE DISCRIMINATOR.\n",
    "            ###########################\n",
    "            \n",
    "            # Select a half-batch of real data and update the discriminator. \n",
    "            number_of_samples = 1\n",
    "            \n",
    "            train_unused_images_indices, real_img_subset, real_img_labels = return_real_images(number_of_samples,\n",
    "                                                                                               train_unused_images_indices)\n",
    "            \n",
    "            d_loss_real, d_accuracy_real = discriminator_model.train_on_batch(real_img_subset, \n",
    "                                                                              real_img_labels)            \n",
    "            print(1)\n",
    "            # Select a half-batch of fake data and update the discriminator. \n",
    "            if real_img_subset.shape[0] < number_of_samples:\n",
    "                number_of_samples = real_images_subset.shape[0] # This checks to see whether we have enough real images to 'fill' the bacth. If not, then we create a smaller number of fake images, equal to the number of real images. We don't want to imbalance the model\n",
    "            \n",
    "            del real_img_subset, real_img_labels # Save memory.\n",
    "\n",
    "            fake_images, fake_image_labels = make_fake_images(generator_model,\n",
    "                                                              latent_length,\n",
    "                                                              number_of_samples)   \n",
    "                      \n",
    "            d_loss_fake, d_accuracy_fake = discriminator_model.train_on_batch(fake_images, \n",
    "                                                                              fake_image_labels)\n",
    "            print(2)\n",
    "            del fake_images, fake_image_labels # Save memory\n",
    "\n",
    "            # Add the discriminator accuracy and loss to our lists.\n",
    "            batch_discriminator_train_loss_real.append(d_loss_real)\n",
    "            batch_discriminator_train_loss_fake.append(d_loss_fake)\n",
    "            batch_discriminator_train_accuracy_real.append(d_accuracy_real)\n",
    "            batch_discriminator_train_accuracy_fake.append(d_accuracy_fake)\n",
    "            \n",
    "            ######################\n",
    "            # TRAIN THE GENERATOR.\n",
    "            ######################\n",
    "            \n",
    "            # Create the latent space. \n",
    "            latent_space = create_latent_space(latent_length,\n",
    "                                               1)\n",
    "            \n",
    "            # Create array of labels... BUT... label as '1', despite the fact that they are fake. \n",
    "            fake_image_labels = np.ones(1)\n",
    "            \n",
    "            with tf.Session() as sess:\n",
    "\n",
    "                # Feed it into the GAN.\n",
    "                generator_loss = gan_model.train_on_batch(latent_space, \n",
    "                                                          fake_image_labels)\n",
    "            print(3)\n",
    "            # Add the generator loss to our list.\n",
    "            batch_generator_train_loss.append(generator_loss)\n",
    "            \n",
    "            #############################\n",
    "            # EVALUATE THE DISCRIMINATOR.\n",
    "            #############################\n",
    "\n",
    "            number_of_samples = 1\n",
    "\n",
    "            # Get the real images. \n",
    "            _, test_images, test_images_labels = return_real_images(number_of_samples,\n",
    "                                                                    test_unused_images_indices)\n",
    "\n",
    "            # Evaluate using the real images. \n",
    "            d_loss_real, d_accuracy_real = discriminator_model.evaluate(test_images, \n",
    "                                                                        test_images_labels,\n",
    "                                                                        verbose = 0)\n",
    "            print(4)\n",
    "            del test_images, test_images_labels # Save memory\n",
    "\n",
    "            # Get the fake images.\n",
    "            test_images, test_images_labels = make_fake_images(generator_model,\n",
    "                                                               latent_length,\n",
    "                                                               number_of_samples)   \n",
    "\n",
    "            d_loss_fake, d_accuracy_fake = discriminator_model.evaluate(test_images, \n",
    "                                                                        test_images_labels,\n",
    "                                                                        verbose = 0)\n",
    "\n",
    "            del test_images, test_images_labels # Save memory\n",
    "            \n",
    "            batch_discriminator_test_loss_real.append(d_loss_real)\n",
    "            batch_discriminator_test_loss_fake.append(d_loss_fake)\n",
    "            batch_discriminator_test_accuracy_real.append(d_accuracy_real)\n",
    "            batch_discriminator_test_accuracy_fake.append(d_accuracy_fake)\n",
    "            \n",
    "            print(5)\n",
    "            \n",
    "            # If we're at the end of the last batch iteration.\n",
    "            if t == (num_batches-1):\n",
    "                \n",
    "                ###############\n",
    "                # LOG THE DATA.\n",
    "                ###############\n",
    "                \n",
    "                # Make an empty list.\n",
    "                epoch_data = []\n",
    "                \n",
    "                # Get the mean values of loss and accuracy. \n",
    "                length = len(batch_discriminator_train_loss_real)\n",
    "                epoch_data.append(sum(batch_discriminator_train_loss_real) / length)\n",
    "                epoch_data.append(sum(batch_discriminator_train_loss_fake) / length)\n",
    "                epoch_data.append(sum(batch_discriminator_train_accuracy_real) / length)\n",
    "                epoch_data.append(sum(batch_discriminator_train_accuracy_fake) / length)\n",
    "                epoch_data.append(sum(batch_generator_train_loss) / length)\n",
    "                \n",
    "                epoch_data.append(sum(batch_discriminator_test_loss_real) / length)\n",
    "                epoch_data.append(sum(batch_discriminator_test_loss_fake) / length)\n",
    "                epoch_data.append(sum(batch_discriminator_test_accuracy_real) / length)\n",
    "                epoch_data.append(sum(batch_discriminator_test_accuracy_fake) / length)\n",
    "\n",
    "                # Add the list to the pandas dataframe. \n",
    "                training_data.loc[len(training_data)] = epoch_data\n",
    "    \n",
    "    # Now that the training is done, save the training data and models, if the user desires it. \n",
    "    if save_data == True: \n",
    "        \n",
    "        # Create the directory if it doesn't already exist. \n",
    "        folder_name = f'training data_{date_time}'\n",
    "        if not os.path.exists(os.path.join(directory, folder_name)):\n",
    "            os.makedirs(os.path.join(directory, folder_name))\n",
    "        \n",
    "        # Save the training data. \n",
    "        file_path = os.path.join(directory, folder_name, 'training_log.csv')\n",
    "        training_data.to_csv(file_path, index=False)\n",
    "        \n",
    "        # Save the models. \n",
    "        file_path = os.path.join(directory, folder_name, f\"GAN_{date_time}.hdf5\")\n",
    "        gan_model.save(file_path) \n",
    "        file_path = os.path.join(directory, folder_name, f\"discriminator_{date_time}.hdf5\")\n",
    "        discriminator_model.save(file_path) \n",
    "        file_path = os.path.join(directory, folder_name, f\"generator_{date_time}.hdf5\")\n",
    "        generator_model.save(file_path) \n",
    "        \n",
    "    # Return function outputs. \n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os \n",
    "from keras.utils.vis_utils import plot_model\n",
    "import pydot \n",
    "import pydotplus\n",
    "import graphviz\n",
    "import time \n",
    "import tensorflow as tf \n",
    "from keras.models import load_model \n",
    "import pandas \n",
    "from pandas import read_csv\n",
    "\n",
    "# Function to train the GAN and save the model outputs. \n",
    "# Function input arg 1: directory [string] --> The directory containing the training data.\n",
    "# Function input arg 2: file_type [string] --> The file type of the training data e.g. '.tif'.\n",
    "# Function input arg 3: save_data [bool] --> When True, saves the models and the training data.\n",
    "# Function input arg 4: num_epochs [int] --> The number of epochs to train for. \n",
    "# Function input arg 5: batch_size [int, preferbly even] --> Num images processed per batch. NB: Your batch size can never equal more than 2*\n",
    "# Function input arg 6: test_train_split [float] --> The fraction of the data which will be used for training. e.g. 0.8 would mean 80% be used for training, while 20% for testing.\n",
    "# Function input arg 7: display_plot [bool] --> When True, prints the graphs of accuracy and loss.\n",
    "# Function input arg 8: train_previous_model [bool] --> When true, the code will continue training a saved model of the user's choice. \n",
    "def train_model(directory,\n",
    "                file_type = '.tif',\n",
    "                save_data = True,\n",
    "                num_epochs = 2,\n",
    "                batch_size = 2,\n",
    "                test_train_split = 0.003,\n",
    "                display_plot=True, \n",
    "                train_previous_model=False):\n",
    "    \n",
    "    ### (1) Establish variables useful for the rest of the code. \n",
    "    \n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # I set up my GPU to run the model, but it doesn't have enough memory, so I'm switching back to CPU. \n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "    ### (2) Load in a saved model to continue it's training, or make a new model. \n",
    "    \n",
    "    # Create and combine our models to make the GAN.\n",
    "    if train_previous_model == False: \n",
    "        \n",
    "        # Create the discriminator. \n",
    "        img = cv2.imread(os.path.join(directory, 'image_1.tif'), -1)\n",
    "        img_height = img.shape[0]\n",
    "        img_width = img.shape[1]\n",
    "        img_channels = 1\n",
    "        discriminator_model = create_discriminator(img_height, \n",
    "                                                   img_width, \n",
    "                                                   img_channels)\n",
    "\n",
    "        # Create the generator. \n",
    "        latent_length = 100 \n",
    "        generator_model = create_generator(latent_length,\n",
    "                                           img_height, \n",
    "                                           img_width)\n",
    "\n",
    "        # Create the GAN.\n",
    "        gan_model = create_GAN(generator_model, discriminator_model)\n",
    "        \n",
    "        # Create an empty pandas dataframe to store the training information.\n",
    "        training_data = pd.DataFrame(columns=['Discriminator training loss real', 'Discriminator training loss fake', 'Discriminator training accuracy real', 'Discriminator training accuracy fake', 'Generator training loss', 'Discriminator testing loss real', 'Discriminator testing loss fake', 'Discriminator testing accuracy real', 'Discriminator testing accuracy fake'])\n",
    "     \n",
    "    # Load in the saved model to continue it's training. \n",
    "    elif train_previous_model == True: \n",
    "        \n",
    "        # Ask the user to select the folder contining the (semi)trained models. \n",
    "        trained_directory = folder_selection_dialog()\n",
    "        \n",
    "        # Load the generator.\n",
    "        generator_name = [_ for _ in os.listdir(trained_directory) if 'generator' in _]\n",
    "        generator_model = load_model(os.path.join(trained_directory, generator_name[0]))\n",
    "        \n",
    "        # Load the discriminator.\n",
    "        discriminator_name = [_ for _ in os.listdir(trained_directory) if 'discriminator' in _]\n",
    "        discriminator_model = load_model(os.path.join(trained_directory, discriminator_name[0]))\n",
    "    \n",
    "        # Create the GAN.\n",
    "        gan_model = create_GAN(generator_model, discriminator_model)\n",
    "\n",
    "        # Load the training data. \n",
    "        training_data = read_csv(os.path.join(trained_directory, 'training_log.csv'))\n",
    "        \n",
    "    ### (3) Plot and save the model architechtures should the user desire it.\n",
    "    folder_name = f'training data_{date_time}'\n",
    "    if save_data == True: \n",
    "\n",
    "        # If the folder to contain training graph etc. doesn't exist, create it. \n",
    "        if not os.path.exists(os.path.join(directory, folder_name)):\n",
    "            os.makedirs(os.path.join(directory, folder_name))\n",
    "\n",
    "        # Save the model architecture. \n",
    "        os.chdir(os.path.join(directory, folder_name))\n",
    "\n",
    "        file_name = f'discriminator_flow_chart_{date_time}.png'\n",
    "        plot_model(discriminator_model, to_file=file_name, show_shapes=True, show_layer_names=True)\n",
    "\n",
    "        file_name = f'generator_flow_chart_{date_time}.png'\n",
    "        plot_model(generator_model, to_file=file_name, show_shapes=True, show_layer_names=True)\n",
    "\n",
    "        file_name = f'GAN_flow_chart_{date_time}.png'\n",
    "        plot_model(gan_model, to_file=file_name, show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    ### (3) Train the GAN. \n",
    "    start = time.time()\n",
    "\n",
    "    training_data = train_GAN(generator_model, \n",
    "                              discriminator_model,\n",
    "                              gan_model,\n",
    "                              latent_length,\n",
    "                              num_epochs,\n",
    "                              batch_size, \n",
    "                              directory, \n",
    "                              file_type, \n",
    "                              test_train_split,\n",
    "                              date_time, \n",
    "                              save_data,\n",
    "                              training_data)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f'{((end-start)/60)}_min')\n",
    "    print(f'{((end-start)/60)/60}_hours')\n",
    "    \n",
    "    ### (4) Use the training_data to plot graphs of the model's loss and accuracy per epoch.\n",
    "        \n",
    "    # Plot the loss. \n",
    "    loss_graph(training_data['Discriminator training loss real'], \n",
    "               training_data['Discriminator training loss fake'],\n",
    "               training_data['Generator training loss'],\n",
    "               training_data['Discriminator testing loss real'],\n",
    "               training_data['Discriminator testing loss fake'],\n",
    "               save_data, \n",
    "               display_plot,\n",
    "               directory, \n",
    "               date_time)\n",
    "    \n",
    "    # Plot the accuracy. \n",
    "    accuracy_graph(training_data['Discriminator training accuracy real'], \n",
    "                   training_data['Discriminator training accuracy fake'],\n",
    "                   training_data['Discriminator testing accuracy real'],\n",
    "                   training_data['Discriminator testing accuracy fake'],\n",
    "                   save_data, \n",
    "                   display_plot,\n",
    "                   directory, \n",
    "                   date_time)\n",
    "    \n",
    "    ### (5) Print the completion statement. \n",
    "    class bcolors:\n",
    "        OKBLUE = '\\033[94m'   \n",
    "        ENDC = '\\033[0m'\n",
    "\n",
    "    print(f'▇▇▇▇▇▇▇▇▇▇▇▇\\nThank you for using this code. The training proces is now complete.\\n\\nPlease refer to the following directory to find your training data:\\n\\n{bcolors.OKBLUE}{os.path.join(directory, folder_name)}{bcolors.ENDC}\\n▇▇▇▇▇▇▇▇▇▇▇▇')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange \n",
    "import numpy as np\n",
    "import os \n",
    "import keras \n",
    "from keras.models import load_model \n",
    "from datetime import datetime \n",
    "from PIL import Image \n",
    "\n",
    "# Function to use a trained generator to create our fake data. \n",
    "# Function input arg 1: number_of_images [int] --> The number of images you wish to generate. \n",
    "def use_generator(number_of_images):\n",
    "    \n",
    "    #### (1) Establish variables important for the code. \n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    #### (2) Load in the previously trained model.\n",
    "    previous_model_path = file_selection_dialog()\n",
    "    generator_model = load_model(previous_model_path, compile=False)\n",
    "    \n",
    "    # Get the parent directory.\n",
    "    directory, _ = os.path.split(previous_model_path)\n",
    "            \n",
    "    # Make the new directory to store the fake images.\n",
    "    if not os.path.exists(os.path.join(directory, 'fake_images')):\n",
    "        os.makedirs(os.path.join(directory, 'fake_images'))\n",
    "        \n",
    "    #### (3) Make and save the images.   \n",
    "    latent_length = 100\n",
    "    for i in (x := trange(number_of_images)):\n",
    "        \n",
    "        # Set the description for the trange progress bar. \n",
    "        x.set_description(f\"Saving fake images:{str(i)}\")\n",
    "        \n",
    "        # Make the fake image.\n",
    "        latent_space = create_latent_space(latent_length, 1)\n",
    "        fake_image = generator_model(latent_space)\n",
    "        fake_image = fake_image[0,:,:,0]\n",
    "        fake_image = (255*(fake_image - np.amin(fake_image))/np.ptp(fake_image)).astype(int)        \n",
    "\n",
    "        # Save the fake image.\n",
    "        file_name = f'fake_image{str(i)}.png'\n",
    "        file_path = os.path.join(directory, 'fake_images', file_name)\n",
    "        im = Image.fromarray(fake_image)\n",
    "        im.save(file_path)\n",
    "    \n",
    "    #### (4) Print a completion statement. \n",
    "    class bcolors:\n",
    "        OKBLUE = '\\033[94m'   \n",
    "        ENDC = '\\033[0m'\n",
    "    print(f'▇▇▇▇▇▇▇▇▇▇▇▇\\nThank you for using this code. The fake images have been made by the generator.\\n\\nPlease refer to the following directory to find them:\\n\\n{bcolors.OKBLUE}{os.path.join(directory)}{bcolors.ENDC}\\n▇▇▇▇▇▇▇▇▇▇▇▇')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out the min number of images neede within dataset for code to work.\n",
    "\n",
    "# Consider removing .predict to avoid the retracing warnings. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
