{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4cdd9b-a6ca-4ad6-8ea9-359a746a1ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "\n",
    "# Function to allow the user to select the folder contianing the data.\n",
    "# Function inputs arg 1: message [string] --> The title for the GUI. \n",
    "# Function output 1: directory [string] --> The path of that the folder selected by the user. \n",
    "def select_folder(message):\n",
    "    root = Tk()\n",
    "    root.title(message)\n",
    "    root.filename = filedialog.askdirectory(initialdir=\"/\", title=message)\n",
    "    directory = root.filename\n",
    "    root.destroy()\n",
    "\n",
    "    return directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c5b0e9-4427-42a4-b130-d4aba7da096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "\n",
    "# Function to allow the user to select the file they need.\n",
    "# Function inputs arg 1: message [string] --> The title for the GUI. \n",
    "# Function output 1: file_directory [string] --> The path of that the folder selected by the user. \n",
    "def select_file(message):\n",
    "    root = Tk()\n",
    "    root.title(message)\n",
    "    root.filename = filedialog.askopenfilename(initialdir=\"/\", title=message)\n",
    "    file_path = root.filename \n",
    "    root.destroy()\n",
    "    \n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76186a10-8c20-4fd3-a54f-1e866efd9a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "from functools import wraps\n",
    "\n",
    "# Decorator in-case I need to optimise code from a temporal point of view. \n",
    "# Decorator input arg 1: f --> The function to be decorated. \n",
    "# Decorator output: timed (string) --> Time taken by decorated function to run (seconds). \n",
    "def timing(f): \n",
    "        \n",
    "    # This ensures that the function metadata (e.g. name, docstring,\n",
    "    # etc.) isn't overwritten when we use the decorator.\n",
    "    @wraps(f) \n",
    "    \n",
    "    def with_timing(*args, **kw):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        result = f(*args, **kw)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f'Time taken (s): {end_time - start_time}')\n",
    "        \n",
    "        return result\n",
    "    return timing     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b43b1-4e9d-4313-a9dd-76f9f658fa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from math import floor \n",
    "from PIL import Image\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt \n",
    "import random\n",
    "import math \n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "\n",
    "# Fucntion to creata a training dataset of images with circles of different areas, and .csv files wth the corresponding area information. \n",
    "# Function input arg 1: num_images [int] --> The number of trainig images you wish to create. \n",
    "def create_training_data(num_images): \n",
    "    \n",
    "    # Select the folder within which you want to create the training dataset directory: 'training-data'.\n",
    "    parent_dir = select_folder('Select the folder within which \"training-data\" will be made')\n",
    "    \n",
    "    # Create the training-data directory. \n",
    "    if not os.path.exists(os.path.join(parent_dir, \"training-data\")):\n",
    "        os.makedirs(os.path.join(parent_dir, 'training-data'))        \n",
    "    \n",
    "    # Create and pandas DataFrame to log away circle area data. \n",
    "    i_data = pd.DataFrame(columns=['imagePath', '10 < x <= 340', '340 < x <= 1000', '1000 < x <= 1700', '1700 < x <= 2500', '2500 < x <= 50000' ])\n",
    "    \n",
    "    # Iteratively produce the training images. \n",
    "    for i in (x := trange(num_images)):\n",
    "        # Set the description for the trange progress bar. \n",
    "        x.set_description(f\"Creating training image:{str(i+1)}\")\n",
    "        \n",
    "        # First create a blank canvas up 0-value pixels. \n",
    "        canvas = np.zeros((256,256))\n",
    "        \n",
    "        # Randomly generate param, such that param can influence the area of the circles. \n",
    "        rand_param = random.randrange(-10, +10, 1)\n",
    "        \n",
    "        # Create an empty list to store the j_list data. \n",
    "        j_list = []\n",
    "        \n",
    "        # Create 9 circles within the image. \n",
    "        for j in range(9):\n",
    "\n",
    "            # Determine the column and row index. \n",
    "            col = ((j%3) + 1) * 64\n",
    "            row  = (floor(j/3) + 1) * 64\n",
    "            \n",
    "            # Get a random radius. \n",
    "            radius = random.randrange(12, 25, 1) + rand_param\n",
    "            \n",
    "            # Set the circle parameters. \n",
    "            center = (col, row)\n",
    "            axes = (radius, radius)\n",
    "            angle = 0\n",
    "            startAngle = 0\n",
    "            endAngle = 360\n",
    "            color = (1)\n",
    "            thickness = -1\n",
    "\n",
    "            # Add the elipse to the image.\n",
    "            cv2.ellipse(canvas, center, axes, angle, startAngle, endAngle, color, thickness)\n",
    "            \n",
    "            # Take note of the area of the circle added to the image.\n",
    "            area = math.pi * radius**2\n",
    "            j_list.append(area)\n",
    "        \n",
    "        # Tally the area sizes into bins.\n",
    "        bins = [10, 340, 1000, 1700, 2500, 50000]\n",
    "        tally = np.ndarray.tolist(np.digitize(np.array(j_list), bins, right=True))\n",
    "        tally_2 = []\n",
    "        for o in range(1, len(bins)):\n",
    "            value = tally.count(o)\n",
    "            tally_2.append(value)\n",
    "        \n",
    "        # Scale the distribution such that it sums to 1. \n",
    "        tally_2 = np.ndarray.tolist(np.array(tally_2) / sum(np.array(tally_2)))\n",
    "        \n",
    "        # Determine the path for the new image. \n",
    "        image_path = os.path.join(parent_dir, 'training-data', f'image_{i}.tif')\n",
    "\n",
    "        # Append the tally to the image path. \n",
    "        i_list = []\n",
    "        i_list.append(image_path)\n",
    "        i_list.extend(tally_2)\n",
    "\n",
    "        # Add the list as a new row to the pandas DataFrame. \n",
    "        i_data.loc[len(i_data)] = i_list\n",
    "\n",
    "        # Save the image. \n",
    "        img = Image.fromarray(canvas)\n",
    "        img.save(image_path)\n",
    "        \n",
    "    # Save the i_data DataFrame. \n",
    "    csv_path = os.path.join(parent_dir, 'training-data', 'area_data.csv')\n",
    "    i_data.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09fa52a-3426-4b92-8145-2ccfadb6f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pandas import read_csv\n",
    "\n",
    "# Function to load in a list of training image paths and their respective distributions. \n",
    "# Function input arg 1: directory [string] --> The directory of training data. \n",
    "# Function output 1: image_paths [list] --> The list of image paths. \n",
    "# Function output 2: distributions [numpy array] --> The distributions.\n",
    "def get_names_and_distributions(directory):\n",
    "    \n",
    "    # First, load in the csv file. \n",
    "    csv_path = os.path.join(directory, 'area_data.csv')\n",
    "    csv_data = read_csv(csv_path)\n",
    "    \n",
    "    # Seperate out the data. \n",
    "    image_paths = [_ for _ in csv_data.iloc[:,0]]\n",
    "    distributions = csv_data.iloc[:,1:6].to_numpy()\n",
    "    \n",
    "    return image_paths, distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e960fd-7cab-4fe4-9b45-ce0f792ce07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Function to display and save the training loss and validation loss per epoch.\n",
    "# Function input arg 1: training_loss --> Array of size 1 x num_epochs. This array contains the calculated values of loss for training. \n",
    "# Function input arg 2: validation_loss --> Array of size 1 x num_epochs. This array contains the calculated values of loss for validation. \n",
    "# Function input arg 3: display_plot --> True or Flase. When true, displays the plot. \n",
    "# Function input arg 4: directory --> The directory containing the training dataset. \n",
    "# Function input arg 5: date_time --> The datetime string in the format of 'YMD_HMS'. \n",
    "def loss_graph(training_loss, \n",
    "               validation_loss, \n",
    "               display_plot,\n",
    "               directory, \n",
    "               date_time):\n",
    "    \n",
    "    # Plot the loss per epoch. \n",
    "    y = list(range(0,len(training_loss)))\n",
    "    plt.plot(y, training_loss, label = \"Training loss\")\n",
    "    plt.plot(y, validation_loss, label = \"Validation loss\")\n",
    "    plt.rcParams.update({'font.size': 20})\n",
    "    plt.ylabel('Loss', labelpad=10) # The labelpad argument alters the distance of the axis label from the axis itself. \n",
    "    plt.xlabel('Epoch', labelpad=10)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    # Save the plot.\n",
    "    folder_name = f'training-data-{date_time}'\n",
    "    if not os.path.exists(os.path.join(directory, folder_name)):\n",
    "        os.makedirs(os.path.join(directory, folder_name))\n",
    "    file_path = os.path.join(directory, folder_name, f'loss_{date_time}.png')\n",
    "    plt.savefig(file_path, dpi=200, bbox_inches='tight')\n",
    "    \n",
    "    # Display the plot if the user desires it. \n",
    "    if (display_plot == False):\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf6048c-bf7d-4859-a59e-52ef2676a466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import os\n",
    "\n",
    "# Function to display the accuary with each training epoch. \n",
    "# Function input arg 1: acc_01 [Array (1 x num_epochs)] --> The training acc with p = 0.1. \n",
    "# Function input arg 2: val_acc_01 [Array (1 x num_epochs)] --> The validation acc with p = 0.1. \n",
    "# Function input arg 3: acc_02 [Array (1 x num_epochs)] --> The validation acc with p = 0.2. \n",
    "# Function input arg 4: val_acc_02 [Array (1 x num_epochs)] --> The validation acc with p = 0.2. \n",
    "# Function input arg 5: acc_03 [Array (1 x num_epochs)] --> The validation acc with p = 0.3. \n",
    "# Function input arg 6: val_acc_03 [Array (1 x num_epochs)] --> The validation acc with p = 0.3. \n",
    "# Function input arg 7: date_time [str] --> The datetime string to add file names. Format: YYYYMMDD_HHMMSS.\n",
    "# Function input arg 8: display_plot [bool] --> True or False. When True, displays the plot while the code is running. \n",
    "# Function input arg 9: directory [str] --> The path to the training_directory.\n",
    "def create_accuracy_graph(acc_01, \n",
    "                          val_acc_01, \n",
    "                          acc_02, \n",
    "                          val_acc_02, \n",
    "                          acc_03, \n",
    "                          val_acc_03, \n",
    "                          date_time,\n",
    "                          display_plot,\n",
    "                          directory):\n",
    "    \n",
    "    # Create the x data. \n",
    "    x = list(range(0,len(acc_01)))\n",
    "    \n",
    "    # Create the accruary plot.\n",
    "    plt.plot(x, acc_01, label=\"Training accuracy, p=0.1\")\n",
    "    plt.plot(x, val_acc_01, label=\"Validation accuracy, p=0.1\")\n",
    "    plt.plot(x, acc_02, label=\"Training accuracy, p=0.2\")\n",
    "    plt.plot(x, val_acc_02, label=\"Validation accuracy, p=0.2\")\n",
    "    plt.plot(x, acc_03, label=\"Training accuracy, p=0.3\")\n",
    "    plt.plot(x, val_acc_03, label=\"Validation accuracy, p=0.3\")\n",
    "    plt.rcParams.update({'font.size': 20})\n",
    "    plt.ylabel('Accuracy', labelpad=11) \n",
    "    plt.xlabel('Epoch', labelpad=11)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    plt.ylim(0,1)\n",
    "    \n",
    "    # Save the plot. \n",
    "    \n",
    "    # If the training_data folder doesn't already exist, create it. \n",
    "    folder_name = f'training-data-{date_time}'\n",
    "    if not os.path.exists(os.path.join(directory, folder_name)):\n",
    "        os.makedirs(os.path.join(directory, folder_name))\n",
    "\n",
    "    # Save the plot. \n",
    "    file_path = os.path.join(directory, folder_name, f'accuracy_{date_time}.png')\n",
    "    plt.savefig(file_path, dpi=250, bbox_inches='tight')\n",
    "    \n",
    "    # Display the plot if the user desires it. \n",
    "    if (display_plot == False):\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f23e4d-0336-4fe0-9530-d49c9c1dfd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to create a graph of circle area distribution data. \n",
    "# Function input arg 1: distribution [array] --> The (n,) distribution array.\n",
    "# Function input arg 2: directory [str] --> When training the model, the training_data path. When testing the model, the testing_data path.\n",
    "# Function input arg 3: display_plot [bool] --> True or False. When True, displays the plot while the code is running. \n",
    "# Function input arg 4: date_time [str] --> The datetime string to label the saves graphs. Formatted as YYYYMMDD_HHMMSS.\n",
    "# Function input arg 5: name_tag [str] --> A string which will be added to the file names. \n",
    "def make_distribution_graph(distribution,\n",
    "                            directory,\n",
    "                            display_plot,\n",
    "                            date_time,\n",
    "                            name_tag='training_'):\n",
    "    \n",
    "    # Create the x data labels.\n",
    "    x = ('10<x<=340', '340<x<=1000', '1000<x<=1700', '1700<x<=2500', '2500<x')\n",
    "    \n",
    "    # Create the x data locations. \n",
    "    x_loc = [0, 1, 2, 3, 4]\n",
    "    \n",
    "    # Calculate the cumulative distribution \n",
    "    c_distribution = []\n",
    "    for j in range(len(distribution)):\n",
    "        array_section = np.array(distribution[0:j+1])\n",
    "        array_sum = sum(array_section)\n",
    "        c_distribution.append(array_sum)\n",
    "    \n",
    "    # Create the graph.\n",
    "    fig, axis_1 = plt.subplots()\n",
    "    axis_2 = axis_1.twinx()\n",
    "    axis_1.bar(x, c_distribution, color = \"green\")\n",
    "    axis_2.bar(x, distribution, color = \"black\")\n",
    "    axis_1.set_xlabel('Circle area (pixels)', fontsize = 15, labelpad=10)\n",
    "    axis_1.set_ylabel('Proportion of circle\\nareas', color='black', fontsize = 15, labelpad=10)\n",
    "    axis_2.set_ylabel('Cumulative proportion of\\ncircle areas', color='green', fontsize = 15, labelpad=10)\n",
    "    axis_1.set_ylim([0, 1.1])\n",
    "    axis_2.set_ylim([0, 1.1])\n",
    "    axis_1.set_xticks(x_loc)\n",
    "    axis_1.set_xticklabels(x, rotation=-45, ha='left', rotation_mode='anchor')\n",
    "    \n",
    "    # Save the plot if the user desires it.\n",
    "\n",
    "    # If the directory doesn't exist, make it. \n",
    "    folder_name = f'prediction-data-{date_time}'\n",
    "    if not os.path.exists(os.path.join(directory, folder_name)):\n",
    "        os.makedirs(os.path.join(directory, folder_name))\n",
    "\n",
    "    # Save the graph.\n",
    "    file_path = os.path.join(directory, folder_name, f'circle_area_{name_tag}.png')\n",
    "    plt.savefig(file_path, dpi=250, bbox_inches='tight')\n",
    "    \n",
    "    # Show the plot with matplotlib if the user desires it. \n",
    "    if (display_plot == False):\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3a2d9-d99c-43d2-bc06-30714d3b87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "import numpy as np\n",
    "import math \n",
    "\n",
    "# Generator class to load in batches of data one by one. \n",
    "class Custom_Generator(keras.utils.all_utils.Sequence) :\n",
    "    \n",
    "    # Initialize the object. \n",
    "    def __init__(self, image_paths, distributions, batch_size, list_idxs, num_channels):\n",
    "        self.image_paths = image_paths\n",
    "        self.distributions = distributions \n",
    "        self.batch_size = batch_size \n",
    "        self.list_idxs = list_idxs\n",
    "        self.num_images = len(self.list_idxs)\n",
    "        self.num_channels = num_channels\n",
    "        self.indexes = np.arange(self.num_images)\n",
    "\n",
    "    # At the start of each epoch, generate a list of indexes and shuffle them such that the batches aren't identical between epochs. \n",
    "    def on_epoch_start(self):\n",
    "        self.indexes = np.random.shuffle(self.indexes) \n",
    "        \n",
    "    # Calculate the number of batches we need.\n",
    "    def __len__(self):\n",
    "\n",
    "        # Flooring prevents empty batches. \n",
    "        return int(math.floor((len(self.image_paths) / float(self.batch_size))))\n",
    "    \n",
    "    # Create one batch of data, where index is the batch number. \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Determine which of our indexes we can use.\n",
    "        start = index*self.batch_size\n",
    "        if (index+1)*self.batch_size > self.num_images:\n",
    "            end = self.num_images\n",
    "        end = (index+1)*self.batch_size\n",
    "        \n",
    "        indexes = self.indexes[start : end]\n",
    "        \n",
    "        # Iteratively construct the x (image) batch. \n",
    "        for i in indexes: \n",
    "            img = cv2.imread(self.image_paths[i], -1)\n",
    "            img = (img - img.min()) / (img.max() - img.min()) \n",
    "            img = np.reshape(img, (1, img.shape[0], img.shape[1], 1))\n",
    "            if indexes[0] - i == 0: \n",
    "                x = img\n",
    "            else: \n",
    "                x = np.append(x, img, axis=0)\n",
    "            \n",
    "        # Construct the y (distribution) batch. \n",
    "        for i in indexes: \n",
    "            distribution = self.distributions[i]\n",
    "            distribution = distribution / sum(distribution)\n",
    "            distribution = np.reshape(distribution, (1, distribution.shape[0]))\n",
    "            if indexes[0] - i == 0: \n",
    "                y = distribution\n",
    "            else: \n",
    "                y = np.append(y, distribution, axis=0)\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c8565a-351a-4f09-96b1-ed22ea568bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization, Activation, Conv2D, Dropout, Add\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Function to create a resusuable identity block (a.k.a. a residual block) for the ResNet. \n",
    "# Function input arg 1: input_layer [array, float 16] --> The input layer. \n",
    "# Function input arg 2: output_filters [int] --> The number of filters passed over the output.\n",
    "# Function output 1: output [array, float 16] --> The output layer. \n",
    "def identity_block(input_layer,\n",
    "                   output_filters):\n",
    "    \n",
    "    # Duplicate the input layer such that it can be used within the skip connection. \n",
    "    input_layer_2 = input_layer\n",
    "\n",
    "    # Perform convolution 1.\n",
    "    conv_1 = Conv2D(output_filters, \n",
    "                    kernel_size=(1,1), \n",
    "                    padding='same', \n",
    "                    kernel_initializer='he_normal', \n",
    "                    kernel_regularizer=regularizers.L1L2(l1=1e-7, l2=1e-7),\n",
    "                    bias_regularizer=regularizers.L2(1e-7),\n",
    "                    activity_regularizer=regularizers.L2(1e-7))(input_layer_2)\n",
    "    batchNorm_1 = BatchNormalization(axis=3)(conv_1)\n",
    "    relu_1 = Activation('relu')(batchNorm_1)\n",
    "\n",
    "    # Perform convolution 2.\n",
    "    conv_2 = Conv2D(output_filters, \n",
    "                     kernel_size=(1,1), \n",
    "                     padding='same', \n",
    "                     kernel_initializer='he_normal',  \n",
    "                     kernel_regularizer=regularizers.L1L2(l1=1e-7, l2=1e-7),\n",
    "                     bias_regularizer=regularizers.L2(1e-7),\n",
    "                     activity_regularizer=regularizers.L2(1e-7))(relu_1)\n",
    "    batchNorm_2 = BatchNormalization(axis=3)(conv_2)\n",
    "    relu_2 = Activation('relu')(batchNorm_2)\n",
    "\n",
    "    # Perform convolution 3. \n",
    "    conv_3 = Conv2D(output_filters, \n",
    "                    kernel_size=(1,1), \n",
    "                    padding='same', \n",
    "                    kernel_initializer='he_normal',  \n",
    "                    kernel_regularizer=regularizers.L1L2(l1=1e-7, l2=1e-7),\n",
    "                    bias_regularizer=regularizers.L2(1e-7),\n",
    "                    activity_regularizer=regularizers.L2(1e-7))(relu_2)\n",
    "    batchNorm_3 = BatchNormalization(axis=3)(conv_3)\n",
    "\n",
    "    # Add the skip connection.\n",
    "    output = Add()([batchNorm_3, input_layer])\n",
    "    \n",
    "    # Add the activation function. \n",
    "    output = Activation('relu')(output)\n",
    "    \n",
    "    # Add dropout. \n",
    "    output = Dropout(0.1)(output)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec211fc-0137-4fff-8030-65623451cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization, Add, Dropout, Conv2D, Activation\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Function to create a reusuable convolutional block. \n",
    "# Function input arg 1: input_layer [array, float 16] --> The input layer. \n",
    "# Function input arg 2: stride [int] --> The stride of the second conv layer. When stride > 1, the image will be pooled. \n",
    "# Function input arg 3: output_filters [int] --> The number of filters passed over the output.  \n",
    "# Function output 1: output_layer [array, float 16] --> The output. \n",
    "def convolutional_block(input_layer,\n",
    "                        stride,\n",
    "                        output_filters):\n",
    "    \n",
    "    # Perform the first convolution\n",
    "    conv_1 = Conv2D(output_filters, \n",
    "                    kernel_size=(1,1), \n",
    "                    padding='same', \n",
    "                    kernel_initializer='he_normal', \n",
    "                    kernel_regularizer=regularizers.L1L2(l1=1e-7, l2=1e-7),\n",
    "                    bias_regularizer=regularizers.L2(1e-7),\n",
    "                    activity_regularizer=regularizers.L2(1e-7))(input_layer)\n",
    "    batchNorm_1 = BatchNormalization(axis=3)(conv_1)\n",
    "    relu_1 = Activation('relu')(batchNorm_1)\n",
    "    \n",
    "    # Perform the second convolution.\n",
    "    conv_2 = Conv2D(output_filters, \n",
    "                    kernel_size=(3,3), \n",
    "                    strides=(stride,stride), \n",
    "                    padding='same', \n",
    "                    kernel_initializer='he_normal',  \n",
    "                    kernel_regularizer=regularizers.L1L2(l1=1e-7, l2=1e-7),\n",
    "                    bias_regularizer=regularizers.L2(1e-7),\n",
    "                    activity_regularizer=regularizers.L2(1e-7))(relu_1)\n",
    "    batchNorm_2 = BatchNormalization(axis=3)(conv_2)\n",
    "    relu_2 = Activation('relu')(batchNorm_2)\n",
    "    \n",
    "    # Perform the third convolution. \n",
    "    conv_3 = Conv2D(output_filters, \n",
    "                    kernel_size=(1,1), padding='same', \n",
    "                    kernel_initializer='he_normal',  \n",
    "                    kernel_regularizer=regularizers.L1L2(l1=1e-7, l2=1e-7),\n",
    "                    bias_regularizer=regularizers.L2(1e-7),\n",
    "                    activity_regularizer=regularizers.L2(1e-7))(relu_2)\n",
    "    batchNorm_3 = BatchNormalization(axis=3)(conv_3)\n",
    "\n",
    "    # Ensure the dimensions are correct.\n",
    "    if  (output_filters == input_layer.shape[-1]) and (batchNorm_3.shape[0] == input_layer.shape[0]) and (batchNorm_3.shape[1] == input_layer.shape[1]):\n",
    "        input_layer_2 = input_layer\n",
    "    else:\n",
    "        input_layer_2 = Conv2D(output_filters, \n",
    "                               kernel_size=(1,1), \n",
    "                               strides=(stride,stride), \n",
    "                               padding='same', \n",
    "                               kernel_initializer='he_normal',  \n",
    "                               kernel_regularizer=regularizers.L1L2(l1=1e-7, l2=1e-7),\n",
    "                               bias_regularizer=regularizers.L2(1e-7),\n",
    "                               activity_regularizer=regularizers.L2(1e-7))(input_layer)\n",
    "        input_layer_2 = BatchNormalization(axis=3)(input_layer_2)\n",
    "    \n",
    "    # Add the skip connection.\n",
    "    output = Add()([batchNorm_3, input_layer_2])\n",
    "    \n",
    "    # Add the activation function. \n",
    "    output = Activation('relu')(output)\n",
    "    \n",
    "    # Add dropout. \n",
    "    output = Dropout(0.1)(output)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d26c451-06b6-4cb6-8863-511e0bd95036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Activation, Dense, Flatten, Lambda, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Function to create a ResNet. \n",
    "# Function input arg 1: input_height [int] --> The height of the input (pixels). \n",
    "# Function input arg 2: input_width [int] --> The width of the image in (pixels). \n",
    "# Function input arg 3: input_channels [int] --> The number of channels. For this project, the inputs have a single channel. \n",
    "def create_resnet(input_height,\n",
    "                  input_width,\n",
    "                  input_channels): \n",
    "    \n",
    "    #####################\n",
    "    # Process the inputs.\n",
    "    #####################\n",
    "    \n",
    "    # Define the input dimensions.\n",
    "    inputs = Input((input_height, input_width, input_channels))\n",
    "    #print(\"inputs:\", inputs.shape)\n",
    "    \n",
    "    # Perform an initial 7x7 convolution to detect features within the input images.\n",
    "    X = Conv2D(64, (7,7), strides=(2,2), kernel_initializer='he_normal', padding='same')(inputs)\n",
    "    \n",
    "    # Batch normalization is used to tackle 'internal covariate shift'. This describes a situation in which inputs are broadly distributed, and seem to change with each batch.\n",
    "    # This can cause the models parameters (especilly those in deep layers) to constantly chase a moving target. \n",
    "    # To help normalize the means and variance of these inputs, batch norm layers are used. \n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    \n",
    "    # Apply an activation function to the sum of weighted inputs.\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Max pooling will downscale the image, but will also identify the most prevalent features within the feature maps. \n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(X)\n",
    "    \n",
    "    ################################################################\n",
    "    # Pass the previous layers to convolutional and identity blocks.\n",
    "    ################################################################\n",
    "    \n",
    "    # Increase the number of filters to 128.\n",
    "    X = convolutional_block(input_layer=X, stride=1, output_filters=128)\n",
    "    X = identity_block(input_layer=X, output_filters=128)\n",
    "    X = identity_block(input_layer=X, output_filters=128)\n",
    "    \n",
    "    # Reduce the image size to 32x32 and increase the number of filters to 256. \n",
    "    X = convolutional_block(input_layer=X, stride=2, output_filters=256)\n",
    "    X = identity_block(input_layer=X, output_filters=256)\n",
    "    X = identity_block(input_layer=X, output_filters=256)\n",
    "    \n",
    "    # Reduce the image size to 16x16. \n",
    "    X = convolutional_block(input_layer=X, stride=2, output_filters=256)\n",
    "    \n",
    "    ################################################################\n",
    "    # Flatten the feature maps to produce an un-scaled distribution.\n",
    "    ################################################################\n",
    "    \n",
    "    # Conv2D layerto reduce the number of filters, followed by ReLu.\n",
    "    X = Conv2D(128, (3,3), kernel_initializer='he_normal', padding='same')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Conv2d layer to reduce the number of filters, followed by ReLu.\n",
    "    X = Conv2D(64, (1,1), kernel_initializer='he_normal', padding='same')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Flatten the image and add dropout.\n",
    "    X = Flatten()(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "    X = Dense(5)(X)\n",
    "    \n",
    "    # A ReLu activation will make sure that our outputs are positive.\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ###########################################################################\n",
    "    # Scale the distribution. Divide each value by the sum of the distribution. \n",
    "    ###########################################################################\n",
    "    \n",
    "    outputs = Lambda(lambda X: X / tf.keras.backend.sum(X, axis=1)[:,None])(X)\n",
    "    \n",
    "    ###########################################\n",
    "    # Finish defining model inputs and outputs.\n",
    "    ###########################################\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caf56f2-2d7d-4c44-abb2-1bfefe3b8118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K \n",
    "\n",
    "# Function to log a pseudo-accuracy. Returns 1 if each value of pred distribution is within p of the corresponding value of the gtruth distribution.\n",
    "# Fucntion input arg 1: p [float] -- > Between 0 and 1. The value described above.\n",
    "# Function output 1: function --> The object. \n",
    "def custom_accuracy(p):\n",
    "    def fn(y_true, y_pred):\n",
    "\n",
    "        # Keras expects data to be symbolic, thus, normal numpy cannot be used. \n",
    "        # Instead, use keras backend functions. \n",
    "        \n",
    "        # Calculate absolute differences between the distributions. \n",
    "        differences = abs(y_true - y_pred)\n",
    "\n",
    "        # Get a boolean representation of the distributions where a difference is less than p. \n",
    "        differences = (differences < p)\n",
    "        differences = K.all(differences, axis=1) \n",
    "\n",
    "        # Take the mean of our boolean tensor. \n",
    "        mean_accuracy = K.mean(differences)\n",
    "\n",
    "        return mean_accuracy\n",
    "\n",
    "    fn_name = str(p).replace(\".\", \"\")\n",
    "    fn.__name__ = 'acc_{}'.format(fn_name)\n",
    "\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daae6501-990d-40e9-9cbb-167127c95005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "# Callback to save the model at regular intervals during training. \n",
    "# Class input 1: interval [int] --> The model will be saved each interval epochs. \n",
    "# Class input 2: directory [string] --> The training directory, as selected by the user early on.\n",
    "# Class input 3: date_time [string] --> The date time string noted when the model is first run. Format: YYYYMMDD_hhmmss.\n",
    "# Class method output 1: model --> The saved keras model. Format: ResNet_YYYYMMDD_hhmmss_Epoch_{epoch}. \n",
    "class SaveModelRegularly(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    # Initialise class attributes. \n",
    "    def __init__(self, interval, directory, date_time):\n",
    "        super().__init__() # This allows us to access the methods of the parent class (the tf callback).\n",
    "        self.interval = interval \n",
    "        self.directory = directory \n",
    "        self.date_time = date_time \n",
    "        \n",
    "    # At the end of the designated epochs, save our model. \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.interval > 0 and epoch%self.interval == 0:\n",
    "            \n",
    "            # We need a directory within which we can save our model.\n",
    "            # If it hasn't been created, create it. \n",
    "            folder_name = f'training-data-{self.date_time}'\n",
    "            if not os.path.exists(os.path.join(self.directory, folder_name)):\n",
    "                os.makedirs(os.path.join(self.directory, folder_name))\n",
    "\n",
    "            # Save our model. \n",
    "            file_path = os.path.join(self.directory, folder_name, f\"ResNet_{self.date_time}_Epoch_{epoch}.h5\")\n",
    "            self.model.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eb67b5-b8d9-4047-8c86-1e78bc78ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd \n",
    "\n",
    "# Function to train the ResNet. \n",
    "# Function input arg 1: num_epochs [int] --> The number of epochs to train the model for. \n",
    "# Function input arg 2: batch_size [int] --> The batch_size. \n",
    "# Function input arg 3: new_model [bool] --> When True, trains a new model. When False, trains a previous model which you select.\n",
    "# Function input arg 4: display_plot [bool] --> When True, prints the plots of loss and accuracy. \n",
    "@timing\n",
    "def train_ResNet(num_epochs, \n",
    "                 batch_size,\n",
    "                 new_model = True, \n",
    "                 display_plot=True):\n",
    "    \n",
    "    ##### (1) First, establish paramaters which will be useful for the rest of the code. \n",
    "    \n",
    "    # Load in the date and time. \n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    #### (2) Get the user to select the directory in question. \n",
    "    \n",
    "    # Select the training directory.\n",
    "    directory = select_folder('Please select the training directory') \n",
    "    \n",
    "    # Generate list of images names and corresponding distributions. \n",
    "    image_paths, distributions = get_names_and_distributions(directory)\n",
    "    \n",
    "    # Split the data into training and testing/validation data. \n",
    "    x_train, x_test, y_train, y_test = train_test_split(image_paths,distributions, test_size=0.2)\n",
    "    \n",
    "    #### (3) Create or load in a model, as the user desires it. \n",
    "    \n",
    "    # Create the new model.\n",
    "    if new_model == True:\n",
    "        \n",
    "        model = create_resnet(256,256,1)\n",
    "        \n",
    "        # Compile the model. \n",
    "        KL_loss = tf.keras.losses.KLDivergence()\n",
    "        optim = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "        model.compile(optimizer=optim,\n",
    "                      loss = KL_loss, \n",
    "                      metrics = ([custom_accuracy(0.1),\n",
    "                                  custom_accuracy(0.2),\n",
    "                                  custom_accuracy(0.3)]))\n",
    "                      \n",
    "    elif new_model == False: \n",
    "        \n",
    "        # Load in the previously trained model.\n",
    "        previous_model_path = select_file()\n",
    "        KL_loss = tf.keras.losses.KLDivergence()\n",
    "        accuracy_01 = custom_accuracy(0.1)\n",
    "        accuracy_02 = custom_accuracy(0.2)\n",
    "        accuracy_03 = custom_accuracy(0.3)\n",
    "        model = load_model(previous_model_path, custom_objects={'KL_loss' : KL_loss,\n",
    "                                                                'acc_01' : accuracy_01,\n",
    "                                                                'acc_02' : accuracy_02,\n",
    "                                                                'acc_03' : accuracy_03})\n",
    "        \n",
    "        # Load in the corresponding pandas data frame containing loss and accuracy.\n",
    "        # NB: When models get loaded in, their old history is not maintained.\n",
    "        _, model_name = os.path.split(previous_model_path)\n",
    "        date_time = re.search('[0-9]+[_][0-9]+', model_name)\n",
    "        date_time = date_time.group(1)\n",
    "        df_name = f'training_log_{date_time}.csv'\n",
    "        df_path = os.path.join(_, df_name)\n",
    "        df = pd.read_csv(log_data_path, index_col=False)\n",
    "        \n",
    "    #### (4) Train the model. \n",
    "\n",
    "    # Create our generators. \n",
    "    list_idxs = np.arange(len(x_train))\n",
    "    training_generator = Custom_Generator(x_train, \n",
    "                                          y_train, \n",
    "                                          batch_size=batch_size,\n",
    "                                          list_idxs=list_idxs, \n",
    "                                          num_channels=1)\n",
    "    list_idxs = np.arange(len(x_test))\n",
    "    validation_generator = Custom_Generator(x_test, \n",
    "                                            y_test, \n",
    "                                            batch_size=batch_size,\n",
    "                                            list_idxs=list_idxs, \n",
    "                                            num_channels=1)\n",
    "\n",
    "    # Train the model. \n",
    "    history = model.fit(training_generator,\n",
    "                        validation_data=validation_generator,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=num_epochs,\n",
    "                        verbose=1, \n",
    "                        callbacks=[SaveModelRegularly(interval = 5,\n",
    "                                                      directory = directory, \n",
    "                                                      date_time = date_time)])\n",
    "    \n",
    "    #### (5) Log the training data.\n",
    "    \n",
    "    # Add the loss and accuracy to the pandas array. \n",
    "    df_temporary = pd.DataFrame()\n",
    "    df_temporary['loss'] = history.history['loss']\n",
    "    df_temporary['val_loss'] = history.history['val_loss']\n",
    "    df_temporary['acc_01'] = history.history['acc_01']\n",
    "    df_temporary['val_acc_01'] = history.history['val_acc_01']\n",
    "    df_temporary['acc_02'] = history.history['acc_02']\n",
    "    df_temporary['val_acc_02'] = history.history['val_acc_02']\n",
    "    df_temporary['acc_03'] = history.history['acc_03']\n",
    "    df_temporary['val_acc_03'] = history.history['val_acc_03']\n",
    "    \n",
    "    # If we need to append our data to that of a previous trainig run, we do it here.\n",
    "    if new_model == True:\n",
    "        df = df_temporary\n",
    "    elif new_model == False:\n",
    "        df = [df, df_temporary]\n",
    "        df = pd.concat(df)\n",
    "        \n",
    "    # Save the model. \n",
    "    folder_name = f'training-data-{date_time}'\n",
    "    if not os.path.exists(os.path.join(directory, folder_name)):\n",
    "        os.makedirs(os.path.join(directory, folder_name))\n",
    "    file_path = os.path.join(directory, folder_name, f\"ResNet_{date_time}.h5\")\n",
    "    model.save(file_path) \n",
    "\n",
    "    # Save the model history (the loss, accuracy, val_loss and val_accuracy).\n",
    "    file_path = os.path.join(directory, folder_name, f\"training_log_{date_time}.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    \n",
    "    #### (6) Plot the data and save it. \n",
    "    \n",
    "    loss_graph(df['loss'], \n",
    "               df['val_loss'], \n",
    "               display_plot=display_plot,\n",
    "               directory=directory, \n",
    "               date_time=date_time)\n",
    "    \n",
    "    create_accuracy_graph(df['acc_01'], \n",
    "                          df['val_acc_01'], \n",
    "                          df['acc_02'], \n",
    "                          df['val_acc_02'], \n",
    "                          df['acc_03'], \n",
    "                          df['val_acc_03'], \n",
    "                          date_time,\n",
    "                          display_plot,\n",
    "                          directory)\n",
    "    \n",
    "    #### (7) Let the user know the model has finished training. \n",
    "    \n",
    "    saved_dir = os.path.join(directory, folder_name)\n",
    "    print(f'██████████████████████\\nTraining complete.\\n\\nModel outputs are stored here:\\n\\n{saved_dir}_{date_time}\\n██████████████████████')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8766a94f-5881-47b7-a820-98bde1f30d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "from keras.models import load_model\n",
    "from tqdm import trange \n",
    "import tensorflow as tf \n",
    "import cv2 \n",
    "import numpy as np \n",
    "\n",
    "# Function to use the trained ResNet on a folder of images. \n",
    "# Function input arg 1: image_ext [list] --> Strings of the image extensions to be considered for processing. \n",
    "def use_resnet(image_ext = ['.tif', '.png']):\n",
    "    \n",
    "    #### (1) First, we establish variables which will be useful later on. \n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    #### (2) Load in our model. \n",
    "    model_path = select_file('Please select the traing model .h5 file')\n",
    "    KL_loss = tf.keras.losses.KLDivergence()\n",
    "    acc_01 = custom_accuracy(0.1)\n",
    "    acc_02 = custom_accuracy(0.2)\n",
    "    acc_03 = custom_accuracy(0.3)\n",
    "    model = load_model(model_path, custom_objects={'KL_loss':KL_loss,\n",
    "                                                   'acc_01':acc_01,\n",
    "                                                   'acc_02':acc_02,\n",
    "                                                   'acc_03':acc_03})\n",
    "    \n",
    "    #### (3) Get a lit of the image paths we need to consider. \n",
    "    directory = select_folder('Please select the folder of images you wish to process')\n",
    "    image_names = [_ for _ in os.listdir(directory) if any(substring in _ for substring in image_ext)]\n",
    "    \n",
    "    #### (4) Iteratively get distributions for each of the images. \n",
    "    for i in trange(len(image_names)):\n",
    "        \n",
    "        # Load in the image. \n",
    "        img = cv2.imread(os.path.join(directory, image_names[i]), -1)\n",
    "        \n",
    "        # Scale the image, just as for training. \n",
    "        img = (img - img.min()) / (img.max() - img.min()) \n",
    "        \n",
    "        # Add batch and channel dimensions. \n",
    "        img = np.reshape(img, (1, img.shape[0], img.shape[1], 1))\n",
    "    \n",
    "        # Save memory and convert to float16. \n",
    "        img = img.astype('float16')\n",
    "        \n",
    "        # Use our model to get a predicted distribution. \n",
    "        distribution = model.predict(img)\n",
    "        distribution = np.reshape(distribution, (5,))\n",
    "        \n",
    "        # Plot and save the distribution \n",
    "        image_name = os.path.splitext(image_names[i])[0]\n",
    "        make_distribution_graph(distribution,\n",
    "                                directory,\n",
    "                                display_plot=True,\n",
    "                                date_time=date_time,\n",
    "                                name_tag=image_name)\n",
    "\n",
    "    #### (5) Let the user know the model has finished training. \n",
    "    \n",
    "    folder_name = f'prediction-data-{date_time}'\n",
    "    saved_dir = os.path.join(directory, folder_name)\n",
    "    print(f'██████████████████████\\nPlotting complete.\\n\\nModel outputs are stored here:\\n\\n{saved_dir}\\n██████████████████████')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
