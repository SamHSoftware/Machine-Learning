{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "\n",
    "# A function to allow the user to select the folder contianing the data.\n",
    "# Function inputs args: None. \n",
    "# Function output 1: The path of that the folder selected by the user. \n",
    "def folder_selection_dialog():\n",
    "    root = Tk()\n",
    "    root.title('Please select the directory containing the images')\n",
    "    root.filename = filedialog.askdirectory(initialdir=\"/\", title=\"Select A Folder\")\n",
    "    directory = root.filename\n",
    "    root.destroy()\n",
    "\n",
    "    return directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "\n",
    "# A function to allow the user to select the model they wish to use or retrain. \n",
    "# Function inputs args: None. \n",
    "# Function output 1: The file path of that which was selected by the user. \n",
    "def file_selection_dialog():\n",
    "    root = Tk()\n",
    "    root.title('Please select the machine learning model in question')\n",
    "    root.filename = filedialog.askopenfilename(initialdir=\"/\", title=\"Select A File\", filetypes=[(\"All files\", \"*.*\")])\n",
    "    file_path = root.filename\n",
    "    root.destroy()\n",
    "\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Function inputs arg 1: num_epochs --> The number of iterations over which the model is refined. \n",
    "# Function inputs arg 2: training_loss --> Array of size 1 x num_epochs. This array contains the calculated values of loss for training. \n",
    "# Function inputs arg 3: validation_loss --> Array of size 1 x num_epochs. This array contains the calculated values of loss for validation. \n",
    "# Function inputs arg 4: save_plot --> True or Flase. When true, saves plot to data directory.  \n",
    "# Function inputs arg 5: display_plot --> True or Flase. When true, displays the plot. \n",
    "# Function output: Graph with the loss per epoch.\n",
    "def loss_graph(num_epochs, \n",
    "               training_loss, \n",
    "               validation_loss, \n",
    "               save_plot, \n",
    "               display_plot):\n",
    "    \n",
    "    # Plot the loss per epoch. \n",
    "    y = list(range(0,num_epochs))\n",
    "    plt.plot(y, training_loss, label = \"Training loss\")\n",
    "    plt.plot(y, validation_loss, label = \"Validation loss\")\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    plt.ylabel('Loss', labelpad=10) # The labelpad argument alters the distance of the axis label from the axis itself. \n",
    "    plt.xlabel('Epoch', labelpad=10)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    # Save the plot if the user desires it.\n",
    "    if save_plot:\n",
    "        current_directory = os.getcwd()\n",
    "        file_path, _ = os.path.split(current_directory)\n",
    "        file_path = os.path.join(file_path, 'img', 'training_and_validation_loss.png')\n",
    "        plt.savefig(file_path, dpi=200, bbox_inches='tight')\n",
    "    \n",
    "    # Display the plot if the user desires it. \n",
    "    if (display_plot == False):\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Function inputs arg 1: num_epochs --> The number of iterations over which the model is refined. \n",
    "# Function inputs arg 2: training_accuracy --> Array of size 1 x num_epochs. This array contains the calculated values of training accuracy. \n",
    "# Function inputs arg 3: validation_accuracy --> Array of size 1 x num_epochs. This array contains the calculated values of validation accuracy. \n",
    "# Function inputs arg 4: save_plot --> True or Flase. When true, saves plot to data directory.  \n",
    "# Function inputs arg 5: display_plot --> True or Flase. When true, displays the plot. \n",
    "# Function output: Graph with the training and validation accuracy per epoch.\n",
    "def accuracy_graph(num_epochs, \n",
    "                   training_accuracy, \n",
    "                   validation_accuracy, \n",
    "                   save_plot, \n",
    "                   display_plot):\n",
    "    \n",
    "    # Plot the BCE calculated loss per epoch. \n",
    "    y = list(range(0,num_epochs))\n",
    "    plt.plot(y, training_accuracy, label=\"Training accuracy\")\n",
    "    plt.plot(y, validation_accuracy, label=\"Validation accuracy\")\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    plt.ylabel('Accuracy', labelpad=10) # The leftpad argument alters the distance of the axis label from the axis itself. \n",
    "    plt.xlabel('Epoch', labelpad=10)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    # Save the plot if the user desires it.\n",
    "    if save_plot:\n",
    "        current_directory = os.getcwd()\n",
    "        file_path, _ = os.path.split(current_directory)\n",
    "        file_path = os.path.join(file_path, 'img', 'training_and_validation_accuracy.png')\n",
    "        plt.savefig(file_path, dpi=200, bbox_inches='tight')\n",
    "    \n",
    "    # Display the plot if the user desires it. \n",
    "    if (display_plot == False):\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from skimage import exposure\n",
    "\n",
    "# A function to display a montage of ground truth data and the predicted data. \n",
    "# Function input arg 1: x_test --> The raw image to display.\n",
    "# Funtion input arg 2: y_test --> The corresponding ground truth labelled image. \n",
    "# Function input arg 3: img_height --> The height of an individual image in pixels. \n",
    "# Function input arg 4: img_width --> the width of an individual image in pixels. \n",
    "# Function output 1: A montage of images, including the raw image, the corresponding ground truth image, and the predicted image. \n",
    "def display_montage(x_test,\n",
    "                    y_test,\n",
    "                    img_height,\n",
    "                    img_width,\n",
    "                    display_plot, \n",
    "                    save_plot):\n",
    "    \n",
    "    # Create the figure.\n",
    "    fig = plt.figure(figsize=(8, 7))\n",
    "\n",
    "    # Set the number of rows and columns. \n",
    "    rows = 2\n",
    "    columns = 3\n",
    "    \n",
    "    # Add a subplot at the 1st position.\n",
    "    fig.add_subplot(rows, columns, 1)\n",
    "    raw_image = exposure.equalize_adapthist(np.squeeze(x_test), clip_limit=0.03)\n",
    "    plt.imshow(raw_image)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Raw Image.\")\n",
    "\n",
    "    # Adds a subplot at the 2nd position\n",
    "    fig.add_subplot(rows, columns, 2)\n",
    "    second_image = np.argmax(np.squeeze(y_test), axis=1)\n",
    "    second_image = second_image.reshape(img_height, img_width)\n",
    "    plt.imshow(second_image, cmap='tab10')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Ground Truth Image.\")\n",
    "    \n",
    "    # Adds a subplot at the 3nd position\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_argmax = np.argmax(y_pred, axis=2)\n",
    "    y_pred_argmax = np.reshape(y_pred_argmax, (img_height, img_width))\n",
    "    \n",
    "    fig.add_subplot(rows, columns, 3)\n",
    "    plt.imshow(y_pred_argmax, cmap='tab10')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Image Predicted by CNN.\")\n",
    "    \n",
    "    # Save the plot if the user desires it.\n",
    "    if save_plot:\n",
    "        current_directory = os.getcwd()\n",
    "        file_path, _ = os.path.split(current_directory)\n",
    "        file_path = os.path.join(file_path, 'img', 'Montage.png')\n",
    "        plt.savefig(file_path, dpi=200, bbox_inches='tight')\n",
    "    \n",
    "    # Display the plot if the user desires it. \n",
    "    if (display_plot == False):\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# A function which will append images within a directory into a numpy array. These imags will also be standardized. \n",
    "# Function input 1: image_list [list of strings] --> Each item in the list is the name of an image which needs to be appended into one stack e.g. image1.tif.\n",
    "# Function input 2: directory [string] --> The directory containing the images.\n",
    "# Function input 3: num_classes_in [numpy array] --> The unique values of the g_truth images. Used for determining the number of classes.\n",
    "# Function input 4: raw [bool] --> When true, will standardize the image mean to 0, and set standard deviation to 1. \n",
    "# Function output 1: image stack [numpy array] --> The 3D stack of appended images. \n",
    "# Function output 2: num_classes_out [numpy array] --> The unique values of the images. Used for determining the number of classes.\n",
    "def append_images(image_list,\n",
    "                  directory, \n",
    "                  num_classes_in,\n",
    "                  raw=True):\n",
    "\n",
    "    # Create an empty list. \n",
    "    image_stack = []\n",
    "    num_classes_out = 0\n",
    "    \n",
    "    # Iterate through the images of our list and append them to our stack. \n",
    "    for i in range(len(image_list)):\n",
    "        file_path = os.path.join(directory, image_list[i])\n",
    "        img = cv2.imread(file_path, -1)\n",
    "        \n",
    "        # For raw images. \n",
    "        if raw: \n",
    "            img = (img - img.min()) / (img.max() - img.min()) # Scale the image between 0 and 1. \n",
    "            #img = np.stack((img,)*num_classes_in, axis=-1)\n",
    "            img = np.stack((img,)*1, axis=-1)\n",
    "            \n",
    "        # For gtruth images. \n",
    "        else: \n",
    "            num_classes_out = len(np.unique(img))\n",
    "            \n",
    "        image_stack.append(img)\n",
    "\n",
    "    # Convert the stack to a numpy array. \n",
    "    image_stack = np.array(image_stack)\n",
    "\n",
    "    return image_stack, num_classes_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model \n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "import tensorflow as tf \n",
    "\n",
    "# A function to create our Unet model. \n",
    "# Function input 1: n_classes [int] --> Number of classes which need to be classified. \n",
    "# Function input 2: img_height [int] --> Image height in pixels. \n",
    "# Function input 3: img_width [int] --> Image width in pixels. \n",
    "# Function input 4: img_channels [int] --> Number of channels. For a grayscale image, this would be 1. for an RGB image, this would be 3.\n",
    "def multiclass_Unet(n_classes = number_classes,\n",
    "                   img_height = img_height,\n",
    "                   img_width = img_width,\n",
    "                   img_channels = img_channels):\n",
    "\n",
    "    inputs = Input((img_height, img_width, img_channels))\n",
    "    #print(\"inputs:\", inputs.shape)\n",
    "    \n",
    "    # Contraction path. \n",
    "    c1 = Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(c1)\n",
    "    #print(\"p1:\", p1.shape)\n",
    "    \n",
    "    c2 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D(2,2)(c2)\n",
    "    #print(\"p2:\", p2.shape)\n",
    "\n",
    "    c3 = Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(c3)\n",
    "    #print(\"p3:\", p3.shape)\n",
    "\n",
    "    c4 = Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(c4)\n",
    "    #print(\"p4:\", p4.shape)\n",
    "\n",
    "    c5 = Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(256, (2,2), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "    #print(\"c5:\", c5.shape)\n",
    "\n",
    "    # Expansion path. \n",
    "    u6 = Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(c5)\n",
    "    #print(\"u6:\", u6.shape)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "    #print(\"c6:\", c6.shape)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(c6)\n",
    "    #print(\"u7:\", u7.shape)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "    #print(\"c7:\", c7.shape)\n",
    "    \n",
    "    u8 = Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(c7)\n",
    "    #print(\"u8:\", u8.shape)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "    #print(\"c8:\", c8.shape)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2,2), strides=(2,2), padding='same')(c8)\n",
    "    #print(\"u9:\", u9.shape)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    c9 = Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "    #print(\"c9:\", c9.shape)\n",
    "\n",
    "    outputs = Conv2D(n_classes, (1,1), activation='softmax')(c9)\n",
    "    outputs = tf.reshape(outputs, [-1, img_height*img_width, n_classes]) # This rehsape is necessary to use sample_weights. \n",
    "    #print(\"outputs:\", outputs.shape)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import class_weight\n",
    "import keras \n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# A function capable of training a CNN to classifying pixels within .tif microscopy images of cell nuclei. \n",
    "# Function input 1: directory [str] --> The directory containing the original and gtruth data. \n",
    "# Function input 2: save_plot [bool] --> When True, graphical data will be saved. \n",
    "# Function input 3: display_plot [bool] --> When True, graphical data will be displayed in the console. \n",
    "# Function input 4: save_model [bool] --> When True, saves the model to the directory containing the training data. \n",
    "# Function output 1: The trained CNN. \n",
    "def train_CNN(directory,\n",
    "              save_plot=False,\n",
    "              display_plot=True,\n",
    "              save_model=True, \n",
    "              num_epochs=30):\n",
    "     \n",
    "    #### (1) Create our training and testing dataset. \n",
    "    \n",
    "    # Get the names of our raw and labelled (gtruth) images. \n",
    "    raw_images = [image for image in os.listdir(directory) if all([image.endswith('.tif'), 'gtruth' not in image])]    \n",
    "    gtruth_images = [image for image in os.listdir(directory) if all([image.endswith('.tif'), 'gtruth' in image])]\n",
    "    \n",
    "    # Get the images (X) and their ground truth equivalents (Y).\n",
    "    Y, number_classes = append_images(gtruth_images, directory, num_classes_in=0, raw = False)\n",
    "    X, _ = append_images(raw_images, directory, num_classes_in=number_classes, raw = True)\n",
    "\n",
    "    # Encode our labels, to ensure that the that the first label value starts from 0 (not 1) as the model expects.\n",
    "    label_encoder = LabelEncoder()\n",
    "    slices, height, width = Y.shape\n",
    "    Y_reshaped = Y.ravel() # Reshape each image into a single column. \n",
    "    Y_reshaped_encoded = label_encoder.fit_transform(Y_reshaped)\n",
    "    Y_reshaped_encoded2 = Y_reshaped_encoded.reshape(slices, height, width)\n",
    "    \n",
    "    # Add an additional dimension to our ground truth data, as the model expects it. \n",
    "    Y = np.expand_dims(Y_reshaped_encoded2, axis = 3)\n",
    "    \n",
    "    # Convert our ground truth pixel values to a one-hot-encoded format. For instance, a pixel value of 2 would be converted to [0,0,1,0]. This is needed for loss functions such as categorical cross entropy loss functions.\n",
    "    Y_categorical = to_categorical(Y, number_classes)\n",
    "    Y_categorical = Y_categorical.reshape((Y.shape[0], Y.shape[1], Y.shape[2], number_classes))\n",
    "    Y_categorical = np.reshape(Y_categorical, (Y_categorical.shape[0], Y_categorical.shape[1]*Y_categorical.shape[2], Y_categorical.shape[3]))\n",
    "    \n",
    "    # Split our data into test and train datasets. \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,Y_categorical, test_size=0.5)\n",
    "\n",
    "    #### (2) Define and the loss algorithm and methods of model assessment. \n",
    "    \n",
    "    # Establish the parameters for the model and the optimizer. \n",
    "    #if number_classes == 2:\n",
    "    #    activation = 'sigmoid' \n",
    "    #elif number_classes > 2:\n",
    "    #    activation = 'softmax'\n",
    "    # Check to see where this will be useful. \n",
    "    \n",
    "    #### (3) Define our model. \n",
    "    \n",
    "    img_height = x_train.shape[1]    \n",
    "    img_width = x_train.shape[2]\n",
    "    img_channels = x_train.shape[3]\n",
    "    model = multiclass_Unet(n_classes = number_classes,\n",
    "                            img_height = img_height,\n",
    "                            img_width = img_width,\n",
    "                            img_channels = img_channels)\n",
    "    \n",
    "    focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "    model.compile(optimizer='adam', loss=focal_loss, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    #### (4) Train our model.\n",
    "    \n",
    "    history = model.fit(x_train,\n",
    "                        y_train,\n",
    "                        batch_size=1,\n",
    "                        epochs=num_epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test,y_test))\n",
    "                        #class_weight=class_weights)\n",
    "    \n",
    "    # If the user desires it, save the entire model as a SavedModel. \n",
    "    if save_model == True:\n",
    "        file_path = os.path.join(directory, 'multiclass_CNN.hdf5')\n",
    "        model.save(file_path) \n",
    "        \n",
    "    #### (5) Assess our model performance. \n",
    "\n",
    "    _, acc = model.evaluate(x_test, y_test)\n",
    "    print(acc)\n",
    "    \n",
    "    # Creat a montage to view data. \n",
    "    display_montage(x_test,\n",
    "                    y_test,\n",
    "                    img_height,\n",
    "                    img_width)\n",
    "    \n",
    "    # Create the loss graph. \n",
    "    loss_graph(num_epochs, \n",
    "               history.history['loss'], \n",
    "               history.history['loss'], \n",
    "               save_plot, \n",
    "               display_plot)\n",
    "    \n",
    "    # Create the accuracy graph. \n",
    "    accuracy_graph(num_epochs, \n",
    "                   history.history['accuracy'], \n",
    "                   history.history['accuracy'], \n",
    "                   save_plot, \n",
    "                   display_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase training dataset size. \n",
    "\n",
    "# Add validation vs training loss. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
