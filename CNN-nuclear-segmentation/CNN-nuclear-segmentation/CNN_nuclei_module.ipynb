{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "\n",
    "# A function to allow the user to select the folder contianing the data.\n",
    "# Function inputs args: None. \n",
    "# Function output 1: The path of that the folder selected by the user. \n",
    "def folder_selection_dialog():\n",
    "    root = Tk()\n",
    "    root.title('Please select the directory containing the images')\n",
    "    root.filename = filedialog.askdirectory(initialdir=\"/\", title=\"Select A Folder\")\n",
    "    directory = root.filename\n",
    "    root.destroy()\n",
    "\n",
    "    return directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Function inputs arg 1: num_epochs --> The number of iterations over which the model is refined. \n",
    "# Function inputs arg 2: training_loss --> Array of size 1 x num_epochs. This array contains the calculated values of loss for training. \n",
    "# Function inputs arg 3: validation_loss --> Array of size 1 x num_epochs. This array contains the calculated values of loss for validation. \n",
    "# Function inputs arg 4: save_plot --> True or Flase. When true, saves plot to data directory.  \n",
    "# Function inputs arg 5: display_plot --> True or Flase. When true, displays the plot. \n",
    "# Function output: Graph with the loss per epoch.\n",
    "def loss_graph(num_epochs, \n",
    "               training_loss, \n",
    "               validation_loss, \n",
    "               save_plot, \n",
    "               display_plot):\n",
    "    \n",
    "    # Plot the loss per epoch. \n",
    "    y = list(range(0,num_epochs))\n",
    "    plt.plot(y, training_loss, label = \"Training loss\")\n",
    "    plt.plot(y, validation_loss, label = \"Validation loss\")\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    plt.ylabel('Loss', labelpad=10) # The labelpad argument alters the distance of the axis label from the axis itself. \n",
    "    plt.xlabel('Epoch', labelpad=10)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    # Save the plot if the user desires it.\n",
    "    if save_plot:\n",
    "        current_directory = os.getcwd()\n",
    "        file_path, _ = os.path.split(current_directory)\n",
    "        file_path = os.path.join(file_path, 'img', 'training_and_validation_loss.png')\n",
    "        plt.savefig(file_path, dpi=200, bbox_inches='tight')\n",
    "    \n",
    "    # Display the plot if the user desires it. \n",
    "    if (display_plot == False):\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Function inputs arg 1: num_epochs --> The number of iterations over which the model is refined. \n",
    "# Function inputs arg 2: training_accuracy --> Array of size 1 x num_epochs. This array contains the calculated values of training accuracy. \n",
    "# Function inputs arg 3: validation_accuracy --> Array of size 1 x num_epochs. This array contains the calculated values of validation accuracy. \n",
    "# Function inputs arg 4: save_plot --> True or Flase. When true, saves plot to data directory.  \n",
    "# Function inputs arg 5: display_plot --> True or Flase. When true, displays the plot. \n",
    "# Function output: Graph with the training and validation accuracy per epoch.\n",
    "def accuracy_graph(num_epochs, \n",
    "               training_accuracy, \n",
    "               validation_accuracy, \n",
    "               save_plot, \n",
    "               display_plot):\n",
    "    \n",
    "    # Plot the BCE calculated loss per epoch. \n",
    "    y = list(range(0,num_epochs))\n",
    "    plt.plot(y, training_accuracy, label=\"Training accuracy\")\n",
    "    plt.plot(y, validation_accuracy, label=\"Validation accuracy\")\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    plt.ylabel('Accuracy', labelpad=10) # The leftpad argument alters the distance of the axis label from the axis itself. \n",
    "    plt.xlabel('Epoch', labelpad=10)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    # Save the plot if the user desires it.\n",
    "    if save_plot:\n",
    "        current_directory = os.getcwd()\n",
    "        file_path, _ = os.path.split(current_directory)\n",
    "        file_path = os.path.join(file_path, 'img', 'training_and_validation_accuracy.png')\n",
    "        plt.savefig(file_path, dpi=200, bbox_inches='tight')\n",
    "    \n",
    "    # Display the plot if the user desires it. \n",
    "    if (display_plot == False):\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# A function which will append images within a directory into a numpy array. These imags will also be standardized. \n",
    "# Function input 1: image_list [list of strings] --> Each item in the list is the name of an image which needs to be appended into one stack e.g. image1.tif.\n",
    "# Function input 2: directory [string] --> The directory containing the images.\n",
    "# Function input 3: num_classes_in [numpy array] --> The unique values of the g_truth images. Used for determining the number of classes.\n",
    "# Function input 4: raw [bool] --> When true, will standardize the image mean to 0, and set standard deviation to 1. \n",
    "# Function output 1: image stack [numpy array] --> The 3D stack of appended images. \n",
    "# Function output 2: num_classes_out [numpy array] --> The unique values of the images. Used for determining the number of classes.\n",
    "def append_images(image_list,\n",
    "                  directory, \n",
    "                  num_classes_in,\n",
    "                  raw=True):\n",
    "\n",
    "    # Create an empty list. \n",
    "    image_stack = []\n",
    "    num_classes_out = 0\n",
    "    \n",
    "    # Iterate through the images of our list and append them to our stack. \n",
    "    for i in range(len(image_list)):\n",
    "        file_path = os.path.join(directory, image_list[i])\n",
    "        img = cv2.imread(file_path, -1)\n",
    "        \n",
    "        # For raw images. \n",
    "        if raw: \n",
    "            img = (img - img.min()) / (img.max() - img.min()) # Scale the image between 0 and 1. \n",
    "            img = np.stack((img,)*num_classes_in, axis=-1)\n",
    "            #img = np.stack((img,)*3, axis=-1)\n",
    "            \n",
    "        # For gtruth images. \n",
    "        else: \n",
    "            num_classes_out = len(np.unique(img))\n",
    "            \n",
    "        image_stack.append(img)\n",
    "\n",
    "    # Convert the stack to a numpy array. \n",
    "    image_stack = np.array(image_stack)\n",
    "\n",
    "    return image_stack, num_classes_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras \n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Model \n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "\n",
    "# A function capable of training a CNN to classifying pixels within .tif microscopy images of cell nuclei. \n",
    "# Function input 1: directory [str] --> The directory containing the original and gtruth data. \n",
    "# Function input 2: save_plot [bool] --> When True, graphical data will be saved. \n",
    "# Function input 3: display_plot [bool] --> When True, graphical data will be displayed in the console. \n",
    "# Function output 1: The trained CNN. \n",
    "def train_CNN(directory,\n",
    "              save_plot=False,\n",
    "              display_plot=True):\n",
    "     \n",
    "    #### (1) Create our training and testing dataset. \n",
    "    raw_images = [image for image in os.listdir(directory) if all([image.endswith('.tif'), 'gtruth' not in image])]    \n",
    "    gtruth_images = [image for image in os.listdir(directory) if all([image.endswith('.tif'), 'gtruth' in image])]\n",
    "    \n",
    "    # Get the images (X) and their ground truth equivalents (Y).\n",
    "    Y, number_classes = append_images(gtruth_images, directory, num_classes_in=0, raw = False)\n",
    "    X, _ = append_images(raw_images, directory, num_classes_in=number_classes, raw = True)\n",
    "\n",
    "    # Encode our labels, to ensure that the that the first label value starts from 0 (not 1) as the model expects.\n",
    "    label_encoder = LabelEncoder()\n",
    "    slices, height, width = Y.shape\n",
    "    Y_reshaped = Y.ravel() # Reshape each image into a single column. \n",
    "    Y_reshaped_encoded = label_encoder.fit_transform(Y_reshaped)\n",
    "    Y_reshaped_encoded = Y_reshaped_encoded.reshape(slices, height, width)\n",
    "    \n",
    "    # Add an additional dimension to our ground truth data, as the model expects it. \n",
    "    Y = np.expand_dims(Y_reshaped_encoded, axis = 3)\n",
    "    \n",
    "    # Convert our ground truth pixel values to a one-hot-encoded format. For instance, a pixel value of 2 would be converted to [0,0,1,0]. This is needed for loss functions such as categorical cross entropy loss functions.\n",
    "    Y_categorical = to_categorical(Y, number_classes)\n",
    "    Y_categorical = Y_categorical.reshape((Y.shape[0], Y.shape[1], Y.shape[2], number_classes))\n",
    "\n",
    "    # Split our data into test and train datasets. \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,Y_categorical, test_size=0.5)\n",
    "    \n",
    "    #### (2) Define and the loss algorithm and methods of model assessment. \n",
    "    \n",
    "    # Establish the parameters for the model and the optimizer. \n",
    "    if number_classes == 2:\n",
    "        activation = 'sigmoid' \n",
    "    elif number_classes > 2:\n",
    "        activation = 'softmax'\n",
    "    \n",
    "    LR = 0.0001\n",
    "    optim = tf.keras.optimizers.Adam(LR)\n",
    "    \n",
    "    # For semantic segmentation, we could use a cross entropy method, but it is suggested to use a combination of loss calculated by dice and focal funcitions. \n",
    "    dice_loss = sm.losses.DiceLoss(class_weights = np.array([0.25,0.25,0.25,0.25]))\n",
    "    focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "    loss_weight = 1\n",
    "    total_loss = dice_loss + (loss_weight * focal_loss) # or simply ... total loss = sm.losses.binary_focal_dice_loss\n",
    "    \n",
    "    # Track the Intersection Over Union (IOU) score and the F-score (a measure of precision and recall).\n",
    "    assessment_scores = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "    \n",
    "    #### (3) Define our model. \n",
    "    \n",
    "    def multiclass_Unet(n_classes = number_classes,\n",
    "                       img_height = height,\n",
    "                       img_width = width,\n",
    "                       img_channels = 1):\n",
    "        \n",
    "    \n",
    "    # Create our encoder. \n",
    "    backbone = 'vgg16'\n",
    "    \n",
    "    # Preprocess our inputs. \n",
    "    preprocessing_method = sm.get_preprocessing(backbone)\n",
    "    x_train = preprocessing_method(x_train)\n",
    "    x_test = preprocessing_method(x_test)\n",
    "    \n",
    "    # Define the model: Unet backbone with resnet34. \n",
    "    model = sm.Unet(backbone, \n",
    "                    encoder_weights='imagenet', \n",
    "                    classes=number_classes, \n",
    "                    activation=activation)\n",
    "\n",
    "    # Compile our keras model together with our optimizer, loss and assessment metrics. \n",
    "    model.compile(optim, total_loss, metrics=assessment_scores)\n",
    "\n",
    "    #### (4) Train our model.\n",
    "    \n",
    "    history = model.fit(x_train,\n",
    "                        y_train,\n",
    "                        batch_size=1,\n",
    "                        epochs=3,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
