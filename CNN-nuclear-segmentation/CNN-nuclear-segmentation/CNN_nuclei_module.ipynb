{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "\n",
    "# A function to allow the user to select the folder contianing the data.\n",
    "# Function inputs args: None. \n",
    "# Function output 1: The path of that the folder selected by the user. \n",
    "def folder_selection_dialog():\n",
    "    root = Tk()\n",
    "    root.title('Please select the directory containing the images')\n",
    "    root.filename = filedialog.askdirectory(initialdir=\"/\", title=\"Select A Folder\")\n",
    "    directory = root.filename\n",
    "    root.destroy()\n",
    "\n",
    "    return directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "\n",
    "# A function to allow the user to select the model they wish to use or retrain. \n",
    "# Function inputs args: None. \n",
    "# Function output 1: The file path of that which was selected by the user. \n",
    "def file_selection_dialog():\n",
    "    root = Tk()\n",
    "    root.title('Please select the machine learning model in question')\n",
    "    root.filename = filedialog.askopenfilename(initialdir=\"/\", title=\"Select A File\", filetypes=[(\"All files\", \"*.*\")])\n",
    "    file_path = root.filename\n",
    "    root.destroy()\n",
    "\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Function to display and save the training loss and validation loss per epoch.\n",
    "# Function input arg 1: training_loss --> Array of size 1 x num_epochs. This array contains the calculated values of loss for training. \n",
    "# Function input arg 2: validation_loss --> Array of size 1 x num_epochs. This array contains the calculated values of loss for validation. \n",
    "# Function input arg 3: save_plot --> True or Flase. When true, saves plot to data directory.  \n",
    "# Function input arg 4: display_plot --> True or Flase. When true, displays the plot. \n",
    "# Function input arg 5: directory --> The directory containing the training dataset. \n",
    "# Function input arg 6: date_time --> The datetime string in the format of 'YMD_HMS'. \n",
    "def loss_graph(training_loss, \n",
    "               validation_loss, \n",
    "               save_plot, \n",
    "               display_plot,\n",
    "               directory, \n",
    "               date_time):\n",
    "    \n",
    "    # Plot the loss per epoch. \n",
    "    y = list(range(0,len(training_loss)))\n",
    "    plt.plot(y, training_loss, label = \"Training loss\")\n",
    "    plt.plot(y, validation_loss, label = \"Validation loss\")\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    plt.ylabel('Loss', labelpad=10) # The labelpad argument alters the distance of the axis label from the axis itself. \n",
    "    plt.xlabel('Epoch', labelpad=10)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    # Save the plot if the user desires it.\n",
    "    if save_plot:\n",
    "        folder_name = f'training data_{date_time}'\n",
    "        if not os.path.exists(os.path.join(directory, folder_name)):\n",
    "            os.makedirs(os.path.join(directory, folder_name))\n",
    "        file_path = os.path.join(directory, folder_name, f'loss_{date_time}.png')\n",
    "        plt.savefig(file_path, dpi=200, bbox_inches='tight')\n",
    "    \n",
    "    # Display the plot if the user desires it. \n",
    "    if (display_plot == False):\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from PIL import Image \n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "import cv2 \n",
    "from tqdm import trange \n",
    "\n",
    "# Function to make a movie from the training data, showing the model training over time.\n",
    "# Function input arg 1: directory --> The directory containing the training dataset. \n",
    "# Function input arg 2: date_time --> The datetime string in the format of 'YMD_HMS'. \n",
    "# Function input arg 3: make_the_movie --> If True, a movie will be made and saved to directory_{date_time}. \n",
    "def make_movie(directory, \n",
    "               date_time, \n",
    "               make_the_movie=True):\n",
    "    \n",
    "    if make_the_movie: \n",
    "\n",
    "        # Determine which images we'll need to load in. \n",
    "        folder_name = f'training data_{date_time}'\n",
    "        image_names = [_ for _ in os.listdir(os.path.join(directory, folder_name)) if 'predicted.png' in _]\n",
    "        number_of_frames = len(image_names)\n",
    "\n",
    "        # Sort out a couple of paths and fonts. \n",
    "        gif_full_path = os.path.join(directory, folder_name, 'animation.gif')\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 100)\n",
    "\n",
    "        # Create the raw image. \n",
    "        raw_img = Image.open(os.path.join(directory, folder_name, 'raw_image.png'))\n",
    "        draw = ImageDraw.Draw(raw_img)\n",
    "        draw.text((20, 20),f'Raw image',font=font, fill=(255))\n",
    "        array = np.array(raw_img)\n",
    "        cmap = plt.cm.gray\n",
    "        raw_image = (cmap(array)*255).astype(np.uint8)\n",
    "\n",
    "        # Create the ground truth labelled image. \n",
    "        gtruth_img = Image.open(os.path.join(directory, folder_name, 'gtruth_image.png'))\n",
    "        draw = ImageDraw.Draw(gtruth_img)\n",
    "        draw.text((20, 20),f'Ground truth image',font=font, fill=(180))\n",
    "        array = np.array(gtruth_img)\n",
    "        cmap = plt.cm.gnuplot2\n",
    "        gtruth_image = (cmap(array)*255).astype(np.uint8)\n",
    "\n",
    "        with imageio.get_writer(gif_full_path, mode='I') as writer:\n",
    "            for x in trange(number_of_frames):\n",
    "\n",
    "                # Create the predicted image. \n",
    "                predicted_img = Image.open(os.path.join(directory, folder_name, f'{str(x)}_predicted.png'))\n",
    "                draw = ImageDraw.Draw(predicted_img)\n",
    "                draw.text((20, 20),f'Predicted image',font=font, fill=(180))\n",
    "                draw.text((20, 2030),f'Epoch: {str(x)}',font=font, fill=(180))\n",
    "                array = np.array(predicted_img)\n",
    "                cmap = plt.cm.gnuplot2\n",
    "                predicted_image = (cmap(array)*255).astype(np.uint8)\n",
    "\n",
    "                # Join all the images together. \n",
    "                image = cv2.hconcat([raw_image, gtruth_image, predicted_image])\n",
    "                \n",
    "                # Save the image. \n",
    "                writer.append_data(image)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Function to display and save the training accuracy and validation accuracy per epoch.\n",
    "# Function input arg 1: training_accuracy --> Array of size 1 x num_epochs. This array contains the calculated values of training accuracy. \n",
    "# Function input arg 2: validation_accuracy --> Array of size 1 x num_epochs. This array contains the calculated values of validation accuracy. \n",
    "# Function input arg 3: save_plot --> True or Flase. When true, saves plot to data directory.  \n",
    "# Function input arg 4: display_plot --> True or Flase. When true, displays the plot. \n",
    "# Function input arg 5: directory --> The directory containing the training dataset. \n",
    "# Function input arg 6: date_time --> The datetime string in the format of 'YMD_HMS'. \n",
    "def accuracy_graph(training_accuracy, \n",
    "                   validation_accuracy, \n",
    "                   save_plot, \n",
    "                   display_plot,\n",
    "                   directory, \n",
    "                   date_time):\n",
    "    \n",
    "    # Plot the BCE calculated loss per epoch. \n",
    "    y = list(range(0,len(training_accuracy)))\n",
    "    plt.plot(y, training_accuracy, label=\"Training accuracy\")\n",
    "    plt.plot(y, validation_accuracy, label=\"Validation accuracy\")\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    plt.ylabel('Accuracy', labelpad=10) # The leftpad argument alters the distance of the axis label from the axis itself. \n",
    "    plt.xlabel('Epoch', labelpad=10)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    # Save the plot if the user desires it.\n",
    "    if save_plot:\n",
    "        folder_name = f'training data_{date_time}'\n",
    "        if not os.path.exists(os.path.join(directory, folder_name)):\n",
    "            os.makedirs(os.path.join(directory, folder_name))\n",
    "        file_path = os.path.join(directory, folder_name, f'accuracy_{date_time}.png')\n",
    "        plt.savefig(file_path, dpi=200, bbox_inches='tight')\n",
    "    \n",
    "    # Display the plot if the user desires it. \n",
    "    if (display_plot == False):\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# A function which will append images within a directory into a numpy array. These imags will also be standardized. \n",
    "# Function input 1: image_list [list of strings] --> Each item in the list is the name of an image which needs to be appended into one stack e.g. image1.tif.\n",
    "# Function input 2: directory [string] --> The directory containing the images.\n",
    "# Function input 3: raw [bool] --> When true, will standardize the image mean to 0, and set standard deviation to 1. \n",
    "# Function output 1: image stack [numpy array] --> The 3D stack of appended images. \n",
    "# Function output 2: num_classes_out [numpy array] --> The unique values of the images. Used for determining the number of classes.\n",
    "def append_images(image_list,\n",
    "                  directory, \n",
    "                  raw=True):\n",
    "\n",
    "    # Create an empty list. \n",
    "    image_stack = []\n",
    "    num_classes_out = 0\n",
    "    \n",
    "    # Iterate through the images of our list and append them to our stack. \n",
    "    for i in range(len(image_list)):\n",
    "        file_path = os.path.join(directory, image_list[i])\n",
    "        img = cv2.imread(file_path, -1)\n",
    "        \n",
    "        # For raw images. \n",
    "        if raw: \n",
    "            \n",
    "            # Scale the image between 0 and 1. \n",
    "            img = (img - img.min()) / (img.max() - img.min()) \n",
    "            \n",
    "            # Höfener, H., Homeyer, A., Weiss, N., Molin, J., Lundström, C.F. and Hahn, H.K., 2018. Deep learning nuclei detection: A simple approach can deliver state-of-the-art results. Computerized Medical Imaging and Graphics, 70, pp.43-52.\n",
    "            # Mirror the data horizontally...\n",
    "            for h in range(2):\n",
    "                if h == 0: \n",
    "                    img2 = img\n",
    "                else:\n",
    "                    img2 = np.flip(img, axis=0) \n",
    "\n",
    "                # ... and vertically. \n",
    "                for v in range(2):\n",
    "                    if v == 0: \n",
    "                        img3 = img2\n",
    "                    else: \n",
    "                        img3 = np.flip(img2, axis=1)\n",
    "            \n",
    "                    # Add an extra axis (for processing later) and append our image to the stack.\n",
    "                    img3 = np.stack((img3,)*1, axis=-1)\n",
    "                    image_stack.append(img3)\n",
    "\n",
    "        # For gtruth images. \n",
    "        else: \n",
    "            num_classes_out = len(np.unique(img))\n",
    "            \n",
    "            # Mirror the data horizontally...\n",
    "            for h in range(2):\n",
    "                if h == 0: \n",
    "                    img2 = img\n",
    "                else:\n",
    "                    img2 = np.flip(img, axis=0) \n",
    "\n",
    "                # ... and vertically. \n",
    "                for v in range(2):\n",
    "                    if v == 0: \n",
    "                        img3 = img2\n",
    "                    else: \n",
    "                        img3 = np.flip(img2, axis=1)\n",
    "            \n",
    "                    # Aappend our image to the stack.\n",
    "                    image_stack.append(img3)\n",
    "    \n",
    "    # Convert the stack to a numpy array. \n",
    "    image_stack = np.asarray(image_stack)\n",
    "\n",
    "    return image_stack, num_classes_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model \n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "import tensorflow as tf \n",
    "\n",
    "# Function to create our Unet model. \n",
    "# Function input 1: n_classes [int] --> Number of classes which need to be classified. \n",
    "# Function input 2: img_height [int] --> Image height in pixels. \n",
    "# Function input 3: img_width [int] --> Image width in pixels. \n",
    "# Function input 4: img_channels [int] --> Number of channels. For a grayscale image, this would be 1. for an RGB image, this would be 3.\n",
    "# Function output 1: The untrained model. \n",
    "def multiclass_Unet(n_classes = number_classes,\n",
    "                   img_height = img_height,\n",
    "                   img_width = img_width,\n",
    "                   img_channels = img_channels):\n",
    "\n",
    "    inputs = Input((img_height, img_width, img_channels))\n",
    "    #print(\"inputs:\", inputs.shape)\n",
    "    \n",
    "    # Contraction path. \n",
    "    c1 = Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(c1)\n",
    "    #print(\"p1:\", p1.shape)\n",
    "    \n",
    "    c2 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D(2,2)(c2)\n",
    "    #print(\"p2:\", p2.shape)\n",
    "\n",
    "    c3 = Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(c3)\n",
    "    #print(\"p3:\", p3.shape)\n",
    "\n",
    "    c4 = Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(c4)\n",
    "    #print(\"p4:\", p4.shape)\n",
    "\n",
    "    c5 = Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(256, (2,2), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "    #print(\"c5:\", c5.shape)\n",
    "\n",
    "    # Expansion path. \n",
    "    u6 = Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(c5)\n",
    "    #print(\"u6:\", u6.shape)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "    #print(\"c6:\", c6.shape)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(c6)\n",
    "    #print(\"u7:\", u7.shape)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "    #print(\"c7:\", c7.shape)\n",
    "    \n",
    "    u8 = Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(c7)\n",
    "    #print(\"u8:\", u8.shape)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "    #print(\"c8:\", c8.shape)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2,2), strides=(2,2), padding='same')(c8)\n",
    "    #print(\"u9:\", u9.shape)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    c9 = Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "    #print(\"c9:\", c9.shape)\n",
    "\n",
    "    outputs = Conv2D(n_classes, (1,1), activation='softmax')(c9)\n",
    "    outputs = tf.reshape(outputs, [-1, img_height*img_width, n_classes]) # This rehsape is necessary to use sample_weights. \n",
    "    #print(\"outputs:\", outputs.shape)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models as sm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import class_weight\n",
    "import keras \n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import load_model \n",
    "from datetime import datetime \n",
    "import pandas as pd \n",
    "from PIL import Image \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# A function capable of training a CNN to classifying pixels within .tif microscopy images of cell nuclei. \n",
    "# Function input 1: directory [str] --> The directory containing the original and gtruth data. \n",
    "# Function input 2: save_plot [bool] --> When True, graphical data will be saved. \n",
    "# Function input 3: display_plot [bool] --> When True, graphical data will be displayed in the console. \n",
    "# Function input 4: save_model [bool] --> When True, saves the model to the directory containing the training data. \n",
    "# Function input 5: train_previous_model [bool] --> When True, the user is prompted to select a previously trained model, in order to continue it's training.\n",
    "# Function input 6: num_epochs [int] --> The number of epochs to train the model.\n",
    "# Function input 7: make_movie [bool] --> When true, outputs a movie of the model learning over time. \n",
    "def train_CNN(directory,\n",
    "              save_plot=True,\n",
    "              display_plot=True,\n",
    "              save_model=True, \n",
    "              train_previous_model=False,\n",
    "              num_epochs=500, \n",
    "              make_the_movie=True):\n",
    "    \n",
    "    #### (1) Establish variables important for the code. \n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    #### (2) Create our training and testing dataset. \n",
    "    \n",
    "    # Get the names of our raw and labelled (gtruth) images. \n",
    "    raw_images = [image for image in os.listdir(directory) if all([image.endswith('.tif'), 'gtruth' not in image])]    \n",
    "    gtruth_images = [image for image in os.listdir(directory) if all([image.endswith('.tif'), 'gtruth' in image])]\n",
    "    \n",
    "    # Get the images (X) and their ground truth equivalents (Y).\n",
    "    Y, number_classes = append_images(gtruth_images, directory, raw = False)\n",
    "    X, _ = append_images(raw_images, directory, raw = True)\n",
    "    \n",
    "    # Encode our labels, to ensure that the that the first label value starts from 0 (not 1) as the model expects.\n",
    "    label_encoder = LabelEncoder()\n",
    "    slices, height, width = Y.shape\n",
    "    Y_reshaped = Y.ravel() # Reshape each image into a single column. \n",
    "    Y_reshaped_encoded = label_encoder.fit_transform(Y_reshaped)\n",
    "    Y_reshaped_encoded2 = Y_reshaped_encoded.reshape(slices, height, width)\n",
    "    \n",
    "    # Add an additional dimension to our ground truth data, as the model expects it. \n",
    "    Y = np.expand_dims(Y_reshaped_encoded2, axis = 3)\n",
    "    \n",
    "    # Convert our ground truth pixel values to a one-hot-encoded format. For instance, a pixel value of 2 would be converted to [0,0,1,0]. This is needed for loss functions such as categorical cross entropy loss functions.\n",
    "    Y_categorical = to_categorical(Y, number_classes)\n",
    "    Y_categorical = Y_categorical.reshape((Y.shape[0], Y.shape[1], Y.shape[2], number_classes))\n",
    "    Y_categorical = np.reshape(Y_categorical, (Y_categorical.shape[0], Y_categorical.shape[1]*Y_categorical.shape[2], Y_categorical.shape[3]))\n",
    "    \n",
    "    # Split our data into test and train datasets. \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,Y_categorical, test_size=0.5)\n",
    "\n",
    "    #### (3) Define the loss algorithm and methods of model assessment. \n",
    "    \n",
    "    # Establish the parameters for the model and the optimizer. \n",
    "    #if number_classes == 2:\n",
    "    #    activation = 'sigmoid' \n",
    "    #elif number_classes > 2:\n",
    "    #    activation = 'softmax'\n",
    "    # Check to see where this will be useful. \n",
    "    \n",
    "    #### (4) Define our new model, or load in a previous model to continue it's training. \n",
    "    \n",
    "    # If we want to make a new model...\n",
    "    if train_previous_model == False: \n",
    "        \n",
    "        # Create the model.\n",
    "        img_height = x_train.shape[1]    \n",
    "        img_width = x_train.shape[2]\n",
    "        img_channels = x_train.shape[3]\n",
    "        model = multiclass_Unet(n_classes = number_classes,\n",
    "                                img_height = img_height,\n",
    "                                img_width = img_width,\n",
    "                                img_channels = img_channels)\n",
    "\n",
    "        focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "        model.compile(optimizer='adam', \n",
    "                      loss=focal_loss, \n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "    # If we want to continue training a previous model... \n",
    "    elif train_previous_model == True:\n",
    "        \n",
    "        # Load in the previously trained model.\n",
    "        previous_model_path = file_selection_dialog()\n",
    "        focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "        model = load_model(previous_model_path, custom_objects={'focal_loss': focal_loss})\n",
    "        \n",
    "        # Load in the corresponding pandas data frame containing loss and accuracy.\n",
    "        # NB: When models get loaded in, their old history is not maintained.\n",
    "        _, model_name = os.path.split(previous_model_path)\n",
    "        date_time = re.search('[0-9]+[_][0-9]+', model_name)\n",
    "        date_time = date_time.group(1)\n",
    "        df_name = f'loss_accuracy_{date_time}.csv'\n",
    "        df_path = os.path.join(_, df_name)\n",
    "        df = pd.read_csv(log_data_path, index_col=False)\n",
    "    \n",
    "    # Create a callback such that the model will save an image montage per epoch. \n",
    "    class SaveMontageCallBack(keras.callbacks.Callback):\n",
    "        def __init__(self, x_test, y_test, img_height, img_width, directory, date_time):\n",
    "            self.x_test = np.expand_dims(x_test[0,:,:,:], 0)\n",
    "            self.y_test = y_test[0,:,:]\n",
    "            self.img_height = img_height\n",
    "            self.img_width = img_width\n",
    "            self.directory = directory\n",
    "            self.date_time = date_time\n",
    "\n",
    "        def on_epoch_end(self, epoch, logs={}): \n",
    "            \n",
    "            print('1')\n",
    "            # Construct the montage of images.\n",
    "            raw_image = exposure.equalize_adapthist(np.squeeze(self.x_test), clip_limit=0.03)\n",
    "            raw_image = (raw_image*255).astype('uint8')\n",
    "            print('2')\n",
    "            gtruth_image = (np.argmax(np.squeeze(self.y_test), axis=1)).reshape(self.img_height, self.img_width)\n",
    "            gtruth_image = (gtruth_image / np.amax(gtruth_image)) * 255\n",
    "            gtruth_image = gtruth_image.astype('uint8')\n",
    "            print('3')\n",
    "            y_pred = model.predict(self.x_test)\n",
    "            y_pred_argmax = np.argmax(y_pred, axis=2)\n",
    "            y_pred_argmax = np.reshape(y_pred_argmax, (self.img_height, self.img_width))\n",
    "            y_pred_argmax = (y_pred_argmax / np.amax(y_pred_argmax)) * 255\n",
    "            y_pred_argmax = y_pred_argmax.astype('uint8')\n",
    "            print('4')\n",
    "            # Create the directory within which we can save the images. \n",
    "            folder_name = f'training data_{self.date_time}'\n",
    "            if not os.path.exists(os.path.join(directory, folder_name)):\n",
    "                os.makedirs(os.path.join(directory, folder_name))\n",
    "                print('5')\n",
    "            # Save the raw and ground truth images (we just need to do it once).\n",
    "            if epoch == 0: \n",
    "                file_path = os.path.join(directory, folder_name, 'raw_image.png')\n",
    "                im = Image.fromarray(raw_image)\n",
    "                im.save(file_path)\n",
    "                print('6')     \n",
    "                \n",
    "                file_path = os.path.join(directory, folder_name, 'gtruth_image.png')\n",
    "                im = Image.fromarray(gtruth_image)\n",
    "                im.save(file_path)\n",
    "                print('7')\n",
    "            # Save the predicted image.\n",
    "            file_name = f'{str(epoch)}_predicted.png'\n",
    "            file_path = os.path.join(directory, folder_name, file_name)\n",
    "            im = Image.fromarray(y_pred_argmax)\n",
    "            im.save(file_path)\n",
    "            \n",
    "    save_montage = SaveMontageCallBack(x_test, y_test, img_height, img_width, directory, date_time)\n",
    "            \n",
    "    #### (5) Train our model.\n",
    "    \n",
    "    history = model.fit(x_train,\n",
    "                        y_train,\n",
    "                        batch_size=1,\n",
    "                        epochs=num_epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test,y_test), \n",
    "                        callbacks=[save_montage])\n",
    "    \n",
    "    # Add the loss and accuracy to the pandas array. \n",
    "    df_temporary = pd.DataFrame()\n",
    "    df_temporary['loss'] = history.history['loss']\n",
    "    df_temporary['accuracy'] = history.history['accuracy']\n",
    "    df_temporary['val_loss'] = history.history['val_loss']\n",
    "    df_temporary['val_accuracy'] = history.history['val_accuracy']\n",
    "    \n",
    "    # If we need to append our data to that of a previous trainig run, we do it here.\n",
    "    if train_previous_model == False:\n",
    "        df = df_temporary\n",
    "    elif train_previous_model == True:\n",
    "        df = [df, df_temporary]\n",
    "        df = pd.concat(df)\n",
    "        \n",
    "    # If the user desires it, save the model as a SavedModel, and save the loss and accuracy values, such that they can be referred to in the instance that a model is loaded in. \n",
    "    if save_model == True:\n",
    "        \n",
    "        # Save the model. \n",
    "        folder_name = f'training data_{date_time}'\n",
    "        if not os.path.exists(os.path.join(directory, folder_name)):\n",
    "            os.makedirs(os.path.join(directory, folder_name))\n",
    "        file_path = os.path.join(directory, folder_name, f\"multiclass_CNN_{date_time}.hdf5\")\n",
    "        model.save(file_path) \n",
    "        \n",
    "        # Save the model history (the loss, accuracy, val_loss and val_accuracy).\n",
    "        file_path = os.path.join(directory, folder_name, f\"loss_accuracy_{date_time}.csv\")\n",
    "        df.to_csv(file_path, index=False)\n",
    "        \n",
    "    #### (6) Assess our model performance. \n",
    "    \n",
    "    # Create the loss graph. \n",
    "    loss_graph(df['loss'], \n",
    "               df['val_loss'], \n",
    "               save_plot, \n",
    "               display_plot,\n",
    "               directory, \n",
    "               date_time)\n",
    "    \n",
    "    # Create the accuracy graph. \n",
    "    accuracy_graph(df['accuracy'], \n",
    "                   df['val_accuracy'], \n",
    "                   save_plot, \n",
    "                   display_plot,\n",
    "                   directory, \n",
    "                   date_time)\n",
    "    \n",
    "    # Create the movie. \n",
    "    make_movie(directory, \n",
    "               date_time, \n",
    "               make_the_movie)\n",
    "    \n",
    "    #### (7) State script completion.\n",
    "    \n",
    "    print(f'===================\\nThe code has finished running.\\n\\nPlease refer to the following directory for the ouputs:\\n\\nf\"{directory}_{date_time}\"\\n\\nThanks for using the code!\\n===================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange \n",
    "import numpy as np\n",
    "import os \n",
    "import keras \n",
    "from keras.models import load_model \n",
    "from datetime import datetime \n",
    "from PIL import Image \n",
    "\n",
    "# Function to use a trained CNN to classify data and save the results in a new directory.\n",
    "def use_CNN():\n",
    "    \n",
    "    #### (1) Establish variables important for the code. \n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Load in the previously trained model.\n",
    "    previous_model_path = file_selection_dialog()\n",
    "    focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "    model = load_model(previous_model_path, custom_objects={'focal_loss': focal_loss})\n",
    "    \n",
    "    # Get the user to select the directory containing the images which need to be classified. \n",
    "    directory = folder_selection_dialog()\n",
    "    \n",
    "    # List images in the directory.\n",
    "    image_names = [_ for _ in os.listdir(directory)]\n",
    "    \n",
    "    # Append all the raw images together\n",
    "    X, _ = append_images(image_names, directory, raw = True)\n",
    "    \n",
    "    # Extract image features. \n",
    "    img_height = X.shape[1]\n",
    "    img_width = X.shape[2]\n",
    "    \n",
    "    # Iterate through the images, classify their pixels, then save the results.\n",
    "    for i in trange(X.shape[0]):\n",
    "        \n",
    "        # Make predictions for each image. \n",
    "        image = np.reshape((X[i,:,:,:]), (1, img_height, img_width, 1))\n",
    "        y_pred = model.predict(image)\n",
    "        y_pred_argmax = np.argmax(y_pred, axis=2)\n",
    "        y_pred_argmax = np.reshape(y_pred_argmax, (img_height, img_width)).astype(np.uint8)\n",
    "        \n",
    "        # Save the predicted image.\n",
    "        file_name = image_names[i]\n",
    "        file_path = os.path.join(directory, 'classified_images', file_name)\n",
    "        \n",
    "        if not os.path.exists(os.path.join(directory, 'classified_images')):\n",
    "            os.makedirs(os.path.join(directory, 'classified_images'))\n",
    "\n",
    "        im = Image.fromarray(y_pred_argmax)\n",
    "        im.save(file_path)\n",
    "    \n",
    "    # Print a completion statement. \n",
    "    print(f'===================\\nThe code has finished running.\\n\\nPlease refer to the following directory for the ouputs:\\n\\nf\"{directory}_classified_images\"\\n\\nThanks for using the code!\\n===================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort out 'Establish the parameters for the model and the optimizer.'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
